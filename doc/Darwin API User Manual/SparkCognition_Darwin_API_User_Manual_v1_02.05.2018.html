<!DOCTYPE html>
<html>
<head>
    <title>SparkCognition Darwin API User Manual v 1.0</title>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
	<style>
		table, th, td {
			border: 1px solid black;
			}
		table {
			border-collapse:collapse;
		}
		.codebox {
			border: 1px solid black ;
			padding: 5px;
			width: 600px;
			Background-color: #EBF5FB;
		}
	</style>
</head>
<body>

<hr />
<img src="graphics/logo.png" width="60%">
<h1>Darwin<sup>&trade;</sup> API User Manual</h1>
<h3>A SparkCognition<sup>&trade;</sup> Education Document</h3> 
<h4>v 1.0 02.02.2018</h4>
<hr />
<h1>Contents</h1>
<p>This document contains the following sections:</p>
<ul>
<li><a href="#about-this-guide">About this guide</a></li>
<li><a href="#overview">Darwin overview</a></li>
<li><a href="#expect">Expectation</a></li>
<li><a href="#route">Technical routes</a>
<ul>
<li><a href="#alyz"><code>analyze</code></a></li>
<li><a href="#auth"><code>auth</code></a></li>
<li><a href="#auth"><code>download</code></a></li>
<li><a href="#lookup"><code>lookup</code></a></li>
<li><a href="#risk"><code>risk</code></a></li>
<li><a href="#run"><code>run</code></a></li>
<li><a href="#status"><code>status</code></a></li>
<li><a href="#train"><code>train</code></a></li>
<li><a href="#uload"><code>upload</code></a></li>
</ul>
</li>
<li><a href="#examp">Examples</a>
<ul>
<li><a href="#log">Login</a>
<ul>
<li><a href="#slogin">Login as service</a></li>
<li><a href="#ulogin">Login as end user</a></li>
</ul>
</li>
<li><a href="#supertrain">Train a model - supervised</a></li>
<li><a href="#ustrain">Train a model - unsupervised</a></li>
<li><a href="#crisk">Create risk data</a></li>
<li><a href="#adaset">Analyze a dataset</a></li>
<li><a href="#anamodel">Analyze a model</a></li>
<li><a href="#testmodel">Test a model</a></li>
<li><a href="#umodel">Model use</a></li>
</ul>
</li>
<li><a href="#reference">Reference</a>
<ul>
<li><a href="#revision">Revision table</a></li>
</ul>
</li>
</ul>
<p>&nbsp;</p>
<p>&nbsp;</p>
<p>&nbsp;</p>
<p>&nbsp;</p>
<hr width="60%" />
<p>&nbsp;</p>
<p>This document contains copyrighted and proprietary information of SparkCognition and is protected by United States copyright laws and international treaty provisions. No part of this publication may be reproduced, stored in a retrieval system or transmitted in any form or by any means, electronic, mechanical, photocopying, recording, scanning or otherwise, except as permitted under such laws or with the prior written permission of  SparkCognition Inc.</p>
<p>SparkCognition<sup>&trade;</sup>, the sparkcognition logo, Darwin<sup>&trade;</sup>, DeepArmor<sup>&reg;</sup>, DeepNLP<sup>&trade;</sup>, MindFabric<sup>&reg;</sup>, SparkSecure<sup>&reg;</sup> and SparkPredict<sup>&trade;</sup>, are trademarks of SparkCognition, Inc. and/or its affiliates and may not be used without written permission. All other trademarks are the property of their respective owners.</p>
<p>&copy;SparkCognition, Inc. 2018. All rights reserved.</p>
<p>&nbsp;</p>
<hr width="60%" />
<h1><a name="about-this-guide">About this guide</a></h1>
<p>This manual describes the Darwin™ API and its use in automated model building.  It is intended for data scientists, software engineers and analysts who want to use the Darwin API to interact with Darwin to create and train models, monitor jobs and perform analysis.</p>
<h1><a name="overview">Darwin overview</a></h1>
<p>Darwin is a SparkCognition<sup>®</sup> tool that automates model building processes to solve specific problems. This tool enhances data scientist potential because it automates various tasks that are often manually performed. These tasks include data cleaning, latent relationship extraction, and optimal model determination. Darwin promotes rapid and accurate feature generation through both automated windowing and risk generation. Darwin quickly creates highly-accurate, dynamic models using both supervised and unsupervised learning methods.<br />
For additional information on Darwin, contact your local SparkCognition partner for access to see the white paper titled: <em>Darwin - A Neurogenesis Platform</em>.</p>
<h2><a name="access">Accessing the API</a></h2>
<p>The Darwin API can normally be accessed through one of three methods:</p>
<ul>
<li>the Darwin Python SDK (preferred, recommended)</li>
<li>through the <code>https://darwin-api.sparkcognition.com/v1</code> end point</li>
<li>optionally, through user created <code>curl</code> commands</li>
</ul>
<p>For additional information on the Darwin SDK, see the <em> Sparkcognition Darwin Python SDK Guide</em>.</p>
<h1><a name="expect">Expectation</a></h1>
<p>This document assumes experience of the data scientist or software engineer that is commensurate with data science  techniques and associated programming tasks.</p>
<h1><a name="route">Technical routes</a></h1>
<p>The Darwin API includes the following api operations:</p>
<ul>
<li><a href="#alyz"><code>analyze</code></a> - analyze a model or dataset</li>
<li><a href="#auth"><code>auth</code></a> - register and authenticate</li>
<li><a href="#auth"><code>download</code></a> - download or delete a generated artifact</li>
<li><a href="#lookup"><code>lookup</code></a> - get model or dataset metadata</li>
<li><a href="#risk"><code>risk</code></a> -  create risk information for a dataset</li>
<li><a href="#status"><code>status</code></a> - return status on jobs</li>
<li><a href="#run"><code>run</code></a> - run a model on a dataset</li>
<li><a href="#train"><code>train</code></a> - train a model</li>
<li><a href="#uload"><code>upload</code></a> - upload or delete a dataset<br />
.</li>
</ul>
<h2><a name="alyz">analyze</a></h2>
<p><strong>Request Type:</strong> POST</p>
<p><strong>URI:</strong> /v1/analyze/model/{model_name}</p>
<p><strong>Headers:</strong></p>
<ul>
<li>Authorization: Bearer token</li>
</ul>
<p><strong>Form Data: </strong></p>
<ul>
<li><em>job_name</em>: The name of the job</li>
<li><em>artifact_name</em>: The name of the artifact</li>
</ul>

<p><strong>Description:</strong> Analyze a model.<br />
<strong>Note</strong>: This API is capable of returning the structure of the model in the form of a png file.</p>
<p><strong>Response Codes:</strong> 201, 400, 401, 403, 422</p>
<p><strong>Successful Response:</strong></p>
  <div class="codebox">
<pre><code>{
  "job_name": "string",
  "artifact_name": "string"
}
</code></pre></div>
<hr />
<p><strong>Request Type:</strong> POST</p>
<p><strong>URI:</strong> /v1/analyze/data/{dataset_name}</p>
<p><strong>Headers:</strong></p>
<ul>
<li>Authorization: Bearer token</li>
</ul>
<p><strong>Description:</strong> Analyze a dataset and return statistics/metadata concerning designated data.</p>
<p><strong>Parameter Descriptions</strong>:</p>
<ul>
<li>
<p><em>target</em>: String denoting target prediction column in input data.</p>
</li>
<li><p><em>job_name</em>: The job name</p></li>
<li>
<p><em>artifact_name</em>: The artifact name.</p>
</li>
<li>
<p><em>impute</em>: String alias that indicates how to fill in missing values in input data.<br />
Descriptions in following table.</p>

<table border="1">
	<col style="width:10%">
	<col style="width:70%">
	<col style="width:20%">
<thead>
<tr>
<th>ALIAS</th>
<th>DESCRIPTION</th>
<th>COMPLEXITY</th>
</tr>
</thead>
<tbody>
<tr>
<td>‘genetic’</td>
<td>Genetic Fill: Automatically determines the most appropriate fast imputation method using evolutionary methods.</td>
<td>Linear <br> Fast</td>
</tr>
<tr>
<td>‘ffill’</td>
<td>(<strong>Default</strong>) Forward Fill: Propagate values forward from one example into the missing cell of the next example. Can be useful for timeseries data, but also applicable for both numerical and categorical data.</td>
<td>Linear<br> Fast</td>
</tr>
<tr>
<td>‘bfill’</td>
<td>Backward Fill: Propagate values backward from one example into the missing cell of the previous example. Can be useful for timeseries data, but also applicable for both numerical and categorical data.</td>
<td>Linear<br> Fast</td>
</tr>
<tr>
<td>‘mean’</td>
<td>Mean Fill: Computes the mean value of all non-missing examples in a column to fill in missing examples. The result might not not be interpretable in terms of the input space for categorical variables.</td>
<td>Linear<br> Fast</td>
</tr>
<tr>
<td>‘median’</td>
<td>Median Fill: Computes the median value of all non-missing examples in a column to fill in missing examples. <br><strong>Note</strong>: Although the result is interpretable in terms of the input space for categorical variables, the approach might not not be appropriate for non-ordinal data.</td>
<td>Linear<br> Fast</td>
</tr>
<tr>
<td>‘mode’</td>
<td>Mode Fill: Uses the most common value on a column-by-column basis to fill in missing examples. The result is interpretable for both numerical and categorical variables.</td>
<td>Linear<br> Fast</td>
</tr>
<tr>
<td>‘spline’</td>
<td>Spline Fill: Interpolation using a spline (piecewise function). Can be useful for timeseries or sequential data.</td>
<td>Linear<br> Fast</td>
</tr>
<tr>
<td>‘linear’</td>
<td>Linear Interpolation Fill: Interpolation using a linear function. Can be useful for timeseries or sequential data.</td>
<td>Linear<br> Fast</td>
</tr>
<tr>
<td>‘knn’</td>
<td>K-Nearest Neighbors Fill: Fills in missing values by averaging the cell values of the k nearest neighbors in the reduced feature space defined by all non-missing columns.</td>
<td>Polynomial <br> Slow</td>
</tr>
<tr>
<td>‘rmf’</td>
<td>Robust Matrix Factorization Fill: Computes low-rank matrices L (observations x rank), R (features x rank), and E where X is input data, and X = LR<sup>T</sup> + E.</td>
<td>Polynomial <br> Slow</td>
</tr>
<tr>
<td>‘mice’</td>
<td>Multiple Imputation by Chained Equations: First imputes missing values using Forward Fill. Then, column-by-column, missing values are reintroduced and regressed upon using the other (non-missing) columns. Continues iteratively.</td>
<td>Polynomial, Iterative <br> Very Slow</td>
</tr>
</tbody>
</table>
</span>
</li>

<li>
<p><em>drop</em>: Enables automatic pruning of input columns based on different criteria such as amount of missing data, number of unique values, and standard deviation.<br />
<strong>Note</strong>: This automatically drops identifier columns (unique value for each sample) and columns that do not contain sufficient data to aid prediction.</p>
</li>
<li>
<p><em>max_int_uniques</em>: Threshold for automatic encoding of categorical variables. If a column contains at least <em>max_int_uniques</em> unique values, it is treated as categorical and one hot encoded during preprocessing.</p>
</li>
<li>
<p><em>max_unique_values</em>: Threshold for automatic pruning of categorical columns prior to one hot encoding based on the number of unique values.<br />
<strong>Note</strong>: If a categorical column contains at least <em>max_unique_values</em>, it is dropped during preprocessing prior to one hot encoding.</p>
</li>
<li>
<p><em>feature_eng</em>: Enables automatic feature generation. Identifies an appropriate time window and augments input with new features derived in the frequency and time domains.<br />
<strong>Notes</strong>: 
<ul>
<li>Can be applied only to timeseries data.</li>
<li>String aliases specify methods for window computation.</li>
</ul></p>

<table border="1">
<thead>
<tr>
<th>Alias</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>None</td>
<td>No feature generation is applied.</td>
</tr>
<tr>
<td>‘mi’</td>
<td>Uses mutual information to estimate the window length.</td>
</tr>
<tr>
<td>‘auc’</td>
<td><em>(Default)</em> Uses autocorrelation to estimate the window length.</td>
</tr>
<tr>
<td>‘user’</td>
<td>User specified window length: see <em>window_len</em>.</td>
</tr>
</tbody>
</table>
</li>
<li>
<p><em>window_len</em>: User specified window length for feature generation.<br />
<strong>Note:</strong> This parameter is used only if <em>user</em> is provided for the <em>feature_eng</em> parameter.</p>
</li>
<li>
<p><em>feature_select</em>: A number in [0,1] that specifies the percentage of numerical features to maintain based on their dependency to the target. Ranks all features using mutual information and drops (1 - feature_select)% of the lowest-ranking features. Default is <strong>1</strong> (keep all features).</p>
</li>
<li>
<p><em>outlier</em>: A string alias that indicates that outlier detection be applied during preprocessing. <br />
<strong>Note:</strong> Outliers are removed and later filled using imputation.</p>

<table border="1">
<thead>
<tr>
<th>Alias</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>None</td>
<td>(Default) No outlier detection is applied.</td>
</tr>
<tr>
<td>‘mad’</td>
<td>Uses Median Absolute Deviation (mad) to detect outliers.</td>
</tr>
<tr>
<td>‘perc’</td>
<td>Uses Percentile-based outlier detection.</td>
</tr>
<tr>
<td>‘isol’</td>
<td>Uses Isolation Forest to detect outliers.</td>
</tr>
</tbody>
</table>
<p><strong>Note</strong>: Outliers are removed and later filled using imputation.</p>
</lI>

</ul>
<p><strong>Payload:</strong></p>
<div class="codebox">
<pre><code>{
  "target": "string",
  "job_name": "string",
  "artifact_name": "string",
  "impute": "mean",
  "drop": true,
  "max_int_uniques": 15,
  "max_unique_values": 50,
  "feature_eng": "auc",
  “window_len”: 10
  "feature_select": 1,
  "outlier": "mad"
}

</code></pre></div>

<p><strong>Response Codes:</strong> 201, 400, 401, 403, 422</p>
<p><strong>Successful Response:</strong></p>
<div class="codebox"><pre><code>{
  "job_name": "string",
  "artifact_name": "string"
}

</code></pre></div>
<hr />
<h2><a name="auth">auth</a></h2>
<p><strong>Request Type:</strong> POST</p>
<p><strong>URI:</strong> /v1/auth/login</p>
<p><strong>Headers:</strong></p>
<ul>
<li>Authorization: Bearer token</li>
</ul>
<p><strong>Description:</strong> Login as a service.</p>
<p><strong>Form Data:</strong></p>
<ul>
<li>
<p><em>api_key</em>: The api key of the service</p>
</li>
<li>
<p><em>pass1</em>: The service level password</p>
</li>
</ul>
<p><strong>Response Codes:</strong> 201, 400, 401</p>
<p><strong>Successful Response:</strong></p>
<div class="codebox">
<pre><code>{
    'access_token': 'some_string'
}
</code></pre></div>
<hr />
<p><strong>Request Type:</strong> POST</p>
<p><strong>URI:</strong> /v1/auth/login/user</p>
<ul>
<li>Authorization: Bearer token</li>
</ul>
<p><strong>Description:</strong> Login as a user.</p>
<p><strong>Form Data:</strong></p>
<ul>
<li>
<p><em>username</em>: The end user name</p>
</li>
<li>
<p><em>pass1</em>: The end user level password</p>
</li>
</ul>
<p><strong>Response Codes:</strong> 201, 400, 401, 422</p>
<p><strong>Successful Response:</strong></p>
<div class="codebox">
<pre><code>{
    'access_token': 'some_string'
}
</code></pre></div>
<hr />
<p><strong>Request Type:</strong> POST</p>
<p><strong>URI:</strong> /v1/auth/register</p>
<p><strong>Headers:</strong></p>
<ul>
<li>Authorization: Bearer token</li>
</ul>
<p><strong>Description:</strong> Register as a service.</p>
<p><strong>Form Data:</strong></p>
<ul>
<li>
<p><em>api_key</em>: The api key of the service</p>
</li>
<li>
<p><em>pass1</em>: The service level password</p>
</li>
<li>
<p><em>pass2</em>: The service level password confirmation</p>
</li>
</ul>
<p><strong>Response Codes:</strong> 201, 400, 401</p>
<p><strong>Successful Response:</strong></p>
<div class="codebox">
<pre><code>{
    'access_token': 'some_string'
}
</code></pre></div>
<hr />
<p><strong>Request Type:</strong> POST</p>
<p><strong>URI:</strong> /v1/auth/register/user</p>
<p><strong>Headers:</strong></p>
<ul>
<li>Authorization: Bearer token</li>
</ul>
<p><strong>Description:</strong> Register a user for your service.</p>
<p><strong>Form Data:</strong></p>
<ul>
<li>
<p><em>username</em>: The end user name</p>
</li>
<li>
<p><em>pass1</em>: The end user level password</p>
</li>
<li>
<p><em>pass2</em>: The end user level password confirmation</p>
</li>
</ul>
<p><strong>Response Codes:</strong> 201, 400, 401, 422</p>
<p><strong>Successful Response:</strong></p>
<div class="codebox">
<pre><code>{
    'access_token': 'some_string'
}
</code></pre></div>
<hr />
<h2><a name="download">download</a></h2>
<p><strong>Request Type:</strong> DELETE</p>
<p><strong>URI:</strong> /v1/download/{artifact_name}</p>
<p><strong>Headers:</strong></p>
<ul>
<li>Authorization: Bearer token</li>
</ul>
<p><strong>Description:</strong> Delete an artifact.</p>
<p><strong>Response Codes:</strong> 204, 401, 404, 422</p>
<p><strong>Successful Response:</strong> None</p>
<hr />


<h2><a name="lookup">lookup</a></h2>

<p><strong>Request Type:</strong> GET</p>
<p><strong>URI:</strong> /v1/lookup/artifact</p>
<p><strong>Headers:</strong>
<ul><li>Authorization: Bearer token</li></ul></p>
<p><strong>Query Parameters:</strong> 
<ul><li>type: filter on the type of artifact (for example. Model, Dataset, Test, Run, or Risk)</li></ul></p>
<p><strong>Description:</strong> Get artifact metadata</p>
<p><strong>Response Codes:</strong> 200, 401, 422</p>
<p><strong>Successful Response:</strong></p>
  <div class="codebox">
<pre><code>
[
  {
    "id": "string",
    "name": "string",
    "type": "string",
    "created_at": "2018-01-22T19:00:39.863Z",
    "mbytes": 0
  }
]
</code></pre></div>
<hr />
<p><strong>Request Type:</strong> GET</p>
<p><strong>URI:</strong> /v1/lookup/artifact/{artifact_name}</p>
<p><strong>Headers:</strong>
<ul><li>Authorization: Bearer token</li></ul></p>
<p><strong>Description:</strong> Get artifact metadata for a single artifact</p>
<p><strong>Response Codes:</strong> 200, 401, 422</p>
<p><strong>Successful Response:</strong></p>
  <div class="codebox">
<pre><code>
{
  "name": "string",
  "type": "string",
  "created_at": "2018-01-22T19:00:39.869Z",
  "mbytes": 0
}
</code></pre></div>
<hr />

<p><strong>Request Type:</strong> GET</p>
<p><strong>URI:</strong> /v1/lookup/model</p>
<p><strong>Headers:</strong></p>
<ul>
<li>Authorization: Bearer token</li>
</ul>
<p><strong>Description:</strong> Get the model metadata for a user. This is useful if a user has<br />
forgotten certain model names.</p>
<p><strong>Response Codes:</strong> 200, 401, 422</p>
<p><strong>Successful Response:</strong></p>
<div class="codebox">
<pre><code>[
    {
        "name": "model1_name",
        "updated_at": "2017-02-03T073000",
        "trained_on": ["dataset1_id", "dataset2_id"],
        "generations": 100,
        "loss": 0.8,
        "parameters": {},
    },
    {
        "name": "model2_name",
        "updated_at": "2017-08-22T175022",
        "trained_on": ["dataset3_id"],
        "loss": 0.82,
        "generations": 80,
        "parameters": {
            "target": "target1"
        },
    }
]
</code></pre></div>
<hr />
<p><strong>Request Type:</strong> GET</p>
<p><strong>URI:</strong> /v1/lookup/client</p>
<p><strong>Headers:</strong></p>
<ul>
<li>Authorization: Bearer token</li>
</ul>
<p><strong>Description:</strong> Get a client’s metadata.</p>
<p><strong>Response Codes:</strong> 200, 401, 422</p>
<p><strong>Successful Response:</strong></p>
<div class="codebox">
<pre><code>{
		"username": "string",
		"tier": 0,
		"model_limit": 0,
		"job_limit": 0,
		"upload_limit": 0,
		"user_limit": 0
		}
</code></pre></div>
<hr />
<p><strong>Request Type:</strong> GET</p>
<p><strong>URI:</strong> /v1/lookup/model/{model_name}</p>
<p><strong>Headers:</strong></p>
<ul>
<li>Authorization: Bearer token</li>
</ul>
<p><strong>Description:</strong> Get all of the model metadata for a particular model.</p>
<p><strong>Response Codes:</strong> 200, 401, 404, 422</p>
<p><strong>Successful Response:</strong></p>
<div class="codebox">
<pre><code>{
    "updated_at": "2017-02-03T073000",
    "trained_on": ["dataset1_id", "dataset2_id"],
    "generations": 100,
    "loss": 0.8,
    "parameters": {},
}
</code></pre></div>
<hr />
<p><strong>Request Type:</strong> GET</p>
<p><strong>URI:</strong> /v1/lookup/dataset</p>
<p><strong>Headers:</strong></p>
<ul>
<li>Authorization: Bearer token</li>
</ul>
<p><strong>Description:</strong> Get the dataset metadata for a user. This is useful if a user<br />
has forgotten certain dataset names.</p>
<p><strong>Response Codes:</strong> 200, 401, 422</p>
<p><strong>Successful Response:</strong></p>
<div class="codebox">
<pre><code>[
    {
        "name": "dataset1_name",
        "mbytes": 0.2,
        "updated_at": "20170924T000000",
        "categorical": False,
        "sequential": True,
        "imbalanced": True,
    },
    {
        "name": "dataset2_name",
        "mbytes": 3.5,
        "updated_at": "20170902T010101",
        "categorical": True,
        "sequential": False,
        "imbalanced": False,
    }
]


</code></pre></div>
<hr />
<p><strong>Request Type:</strong> GET</p>
<p><strong>URI:</strong> /v1/lookup/dataset/{dataset_name}</p>
<p><strong>Headers:</strong></p>
<ul>
<li>Authorization: Bearer token</li>
</ul>
<p><strong>Description:</strong> Get all of the dataset metadata for a particular dataset.</p>
<p><strong>Response Codes:</strong> 200, 401, 404, 422</p>
<p><strong>Successful Response:</strong></p>
<div class="codebox">
<pre><code>{
    'mbytes': 0.2,
    'updated_at': '20170924T000000',
    'categorical': False,
    'sequential': True,
    'imbalanced': True,
}

</code></pre></div>
<hr />
<p><strong>Request Type:</strong> GET</p>
<p><strong>URI:</strong> /v1/lookup/tier</p>
<p><strong>Headers:</strong></p>
<ul>
<li>Authorization: Bearer token</li>
</ul>
<p><strong>Description:</strong> Get all of the tier metadata.</p>
<p><strong>Response Codes:</strong> 200, 401, 422</p>
<p><strong>Successful Response:</strong></p>
<div class="codebox">
<pre><code>[
  {
    &quot;tier&quot;: 0,
    &quot;model_limit&quot;: 0,
    &quot;job_limit&quot;: 0,
    &quot;upload_limit&quot;: 0,
    &quot;user_limit&quot;: 0
  }
]

</code></pre></div>
<hr />
<p><strong>Request Type:</strong> GET</p>
<p><strong>URI:</strong> /v1/lookup/tier/{tier_num}</p>
<p><strong>Headers:</strong></p>
<ul>
<li>Authorization: Bearer token</li>
</ul>
<p><strong>Description:</strong> Get the metadata for a particular tier.</p>
<p><strong>Response Codes:</strong> 200, 401, 404, 422</p>
<p><strong>Successful Response:</strong></p>
<div class="codebox">
<pre><code>{
  &quot;tier&quot;: 0,
  &quot;model_limit&quot;: 0,
  &quot;job_limit&quot;: 0,
  &quot;upload_limit&quot;: 0,
  &quot;user_limit&quot;: 0
}

</code></pre></div>
<hr />
<h2><a name="risk">risk</a></h2>
<p><strong>Notes concerning risk</strong> - <br /><em>risk</em> is a value used in calculating future events. A risk is calculated using algorithms based on sliding time frames and associated historical data that projects forward in time to predict the likelihood of the event. The outcome of the calculations is that the likelihood of an event occurring within a particular time frame becomes available for use. Note that risk values are dependent on the quality and extent of the historical data as well as the scope of the timeframe used for evaluation.</p>
<p><strong>Request Type:</strong> POST</p>
<p><strong>URI:</strong> /risk/{failure_data}/{timeseries_data}</p>
<p><strong>Headers:</strong></p>
<ul>
<li>Authorization: Bearer token</li>
</ul>
<p><strong>Description:</strong>  Create risk information for a dataset.</p>
<p><strong>Parameter Descriptions:</strong></p>
<ul>
<li><em>job_name</em>: The job name.</li>
<li><em>artifact_name</em>: The artifact name.</li>
<li><em>risk_columns</em>: A list of column names in the index.</li>
<li>
<p><em>shutdown_column</em>: Name of the column in the risk data that denotes the beginning of the predicted event of interest.</p>
</li>
<li>
<p><em>return_column</em>: Name of the column in the risk data that denotes the end of the predicted event <em>and</em> when all data can again be considered “normal”.</p>
</li>
<li>
<p><em>asset_column</em>: Name of the asset column in the risk data. This parameter is used when the datasets consist of multiple different assets.</p>
</li>
<li>
<p><em>lead_time</em>: Lead time in seconds. This value is half width of the risk function - this means. the risk index is 0 prior to <em>2* lead_time</em> and increases to 1 at a failure time.<br /><strong>Note:</strong>The <em>lead_time</em>value must be greater than zero.</p>
</li>
<li>
<p><em>Functional_form</em>: Shape of a risk function, includes:</p>
<ul>
<li><code>step</code>: Step function</li>
<li><code>linear</code>: Linear function</li>
<li><code>sigmoid</code>: Sigmoid function</li>
<li><code>exponential</code>: Exponential function</li>
</ul>
</li>
</ul>
<p><strong>Payload:</strong></p>
<div class="codebox">
<pre><code>{
  "target": "string",
  "job_name": "string",
  "risk_columns": [
    "risk"
  ],
  "shutdown_column": "Shutdown Time",
  "return_column": "Return Time",
  "asset_column": "Asset",
  "lead_time": 1,
  "functional_form": "linear"
}

</code></pre></div>
<p><strong>Response Code:</strong> 201, 400, 401, 403, 404, 422</p>
<p><strong>Successful Response:</strong></p>
<div class="codebox">
<pre><code>{
    "job_name": "job1_name",
    "artifact_name": "some string",
}
</code></pre></div>
<hr />
<h2><a name="run">run</a></h2>
<p><strong>Request Type:</strong> POST</p>
<p><strong>URI:</strong> /v1/run/model/{model_name}/{dataset_name}</p>
<p><strong>Headers:</strong></p>
<ul>
<li>Authorization: Bearer token</li>
</ul>
<p><strong>Form Data:</strong></p>
<ul>
<li><em>job_name</em>: The name of the job.</li>
<li><em>artifact_name</em>: The name of the artifact.</li>
<li><em>supervised</em>: A boolean (true/false) indicating whether the model is supervised or not, for example <em>unsupervised</em>.</li>
</ul>
<p><strong>Description:</strong> Run a model on a dataset and return the<br />
predictions/classifications/clusters found by the model.</p>
<p><strong>Response Codes:</strong> 201, 400, 401, 403, 404, 408, 422</p>
<p><strong>Successful Response:</strong></p>
<div class="codebox">
<pre><code>{
    "job_name": "job1_name",
    "artifact_name": "artifact1_name"
}
</code></pre></div>
<hr />
<h2><a name="status">status</a></h2>
<p><strong>Request Type:</strong> GET</p>
<p><strong>URI:</strong> /v1/job/status</p>
<p><strong>Headers:</strong></p>
<ul>
<li>Authorization: Bearer token</li>
</ul>
<p><strong>Query Parameters:</strong></p>
<ul>
<li>Age: List jobs that are less than X units old (for example, 3 weeks, 2 days)</li>
<li>Status: List job of a particular status, for example <em>Running</em></li>
</ul>
<p><strong>Description:</strong> Get the status for all jobs.</p>
<p><strong>Response Codes:</strong> 200, 400, 401, 422</p>
<p><strong>Successful Response:</strong></p>
<div class="codebox">
<pre><code> 
[
    {
        "job_name": "job1_name",
        "status": "Requested",
			"starttime": "2018-01-30T13:27:46.449865",
       "endtime": "2018-01-30T13:28:46.449865",
        "percent_complete": 0,
       "job_type": "TrainModel",		
        "loss": 0,
        "generations": 0,
        "dataset_names": [
            "phone_data"
        ],
        "artifact_names": [
            "art1"
        ]
        "model_name": null,
    },
    {
        "job_name": "job2_name",
        "status": "Running",
        "starttime": "2018-01-30T13:27:46.449865",
        "endtime": "2018-01-30T13:28:46.449865",
        "percent_complete": 23,
        "job_type": "UpdateModel",
        "loss": 0.92,
        "generations": 50,
        "dataset_names": [
            "language_data"
        ],
        "artifact_names": null,
        "model_name": "test_model",
    }
]

</code></pre></div>
<hr />

<p><strong>Request Type:</strong> GET</p>
<p><strong>URI:</strong> /v1/job/status/{job_name}</p>
<p><strong>Headers:</strong></p>
<ul>
<li>Authorization: Bearer token</li>
</ul>
<p><strong>Query Parameters:</strong></p>
<ul>
<li>Age: List jobs that are less than X units old (for example, 3 weeks, 2 days)</li>
</ul>
<p><strong>Description:</strong> Get the status for a particular job.</p>
<p><strong>Response Codes:</strong> 200, 400, 401, 404, 422</p>
<p><strong>Successful Response:</strong></p>
<div class="codebox">
<pre><code>{
    "status": "Requested",
	"starttime": "2018-01-30T13:27:46.449865",
    "endtime": "2018-01-30T13:28:46.449865",
    "percent_complete": 0,
    "job_type": "TrainModel",
    "loss": 0,
    "generations": 0,
    "dataset_names": [
        "language_data"
    ],
    "artifact_names": null,
    "model_name": None,
}

</code></pre></div>
<hr />
<h2><a name="train">train</a></h2>
<p><strong>Request Type:</strong> POST</p>
<p><strong>URI:</strong> /v1/train/model</p>
<p><strong>Headers:</strong></p>
<ul>
<li>Authorization: Bearer token</li>
</ul>
<p><strong>Description:</strong> Create a model trained on the dataset identified by dataset_name.</p>
<p><strong>Parameter descriptions:</strong></p>
<ul>
<li>
<p><em>target</em>: String denoting target prediction column in input data.</p>
</li>
<li>
<p><em>dataset_names</em>: A list of dataset names to use for training. <br /><strong>Note:</strong> only 1 is currently supported.</p>
</li>
<li>
<p><em>job_name</em>: The job name.</p>
</li>
<li>
<p><em>model_name</em>: The string identifier of the model to be trained.</p>
</li>
<li>
<p><em>max_train_time</em>: Sets the training time for the model in ‘HH:MM’ format.<br />
<strong>Note</strong>: This overrides any values set for <em>max_generation</em>.</p>
</li>
<li>
<p><em>max_generation</em>: Expected input/type: <em>numeric</em>. Sets the training time for the model in generations. If <em>max_train_time</em> is set, this parameter is ignored.</p>
</li>
<li>
<p><em>recurrent</em>: Expected input/type: <em>true/false</em>. Enables recurrent connections to be evolved in the model. This option can be useful for timeseries or sequential data.<br />
<strong>Note</strong>:  This option is automatically enabled if a <em>datetime</em> column is detected in the input data. This can result in slower model evolution.</p>
</li>
<li>
<p><em>impute</em>: String alias that indicates how to fill in missing values in input data.</p>

<table border="1">
	<col style="width:10%">
	<col style="width:70%">
	<col style="width:20%">
<thead>
<tr>
<th>ALIAS</th>
<th>DESCRIPTION</th>
<th>COMPLEXITY</th>
</tr>
</thead>
<tbody>
<tr>
<td>‘genetic’</td>
<td>Genetic Fill: Automatically determines the most appropriate fast imputation method using evolutionary methods.</td>
<td>Linear<br />Fast</td>
</tr>
<tr>
<td>‘ffill’</td>
<td><strong>(Default)</strong> Forward Fill: Propagate values forward from one example into the missing cell of the next example. Might be useful for timeseries data, but also applicable for both numerical and categorical data.</td>
<td>Linear <br> Fast</td>
</tr>
<tr>
<td>‘bfill’</td>
<td>Backward Fill: Propagate values backward from one example into the missing cell of the previous example. Might be useful for timeseries data, but also applicable for both numerical and categorical data.</td>
<td>Linear <br> Fast</td>
</tr>
<tr>
<td>‘mean’</td>
<td>Mean Fill: Computes the mean value of all non-missing examples in a column to fill in missing examples. The result may or might not be interpretable in terms of the input space for categorical variables.</td>
<td>Linear <br> Fast</td>
</tr>
<tr>
<td>‘median’</td>
<td>Median Fill: Computes the median value of all non-missing examples in a column to fill in missing examples. While the result is interpretable in terms of the input space for categorical variables, the approach might not be appropriate for non-ordinal data.</td>
<td>Linear <br> Fast</td>
</tr>
<tr>
<td>‘mode’</td>
<td>Mode Fill: Uses the most common value on a column-by-column basis to fill in missing examples. The result is interpretable for both numerical and categorical variables.</td>
<td>Linear <br> Fast</td>
</tr>
<tr>
<td>‘spline’</td>
<td>Spline Fill: Interpolation using a spline (piecewise function). Might be useful for timeseries or sequential data.</td>
<td>Linear <br> Fast</td>
</tr>
<tr>
<td>‘linear’</td>
<td>Linear Interpolation Fill: Interpolation using a Linear function. Might be useful for timeseries or sequential data.</td>
<td>Linear <br> Fast</td>
</tr>
<tr>
<td>‘knn’</td>
<td>K-Nearest Neighbors Fill: Fills in missing values by averaging the cell values of the k nearest neighbors in the reduced feature space defined by all non-missing columns.</td>
<td>Polynomial <br> Slow</td>
</tr>
<tr>
<td>‘rmf’</td>
<td>Robust Matrix Factorization Fill: Computes low-rank matrices L (observations x rank), R (features x rank), and E where X is input data, and X = LR<sup>T</sup> + E.</td>
<td>Polynomial <br>Slow</td>
</tr>
<tr>
<td>‘mice’</td>
<td>Multiple Imputation by Chained Equations: First imputes missing values using <em>Forward Fill</em>. Then, column-by-column, missing values are reintroduced and regressed upon using the other (non-missing) columns. Continues iteratively.</td>
<td>Polynomial, Iterative <br>Very Slow</td>
</tr>
</tbody>
</table>
</li>
<li>
<p><em>drop</em>: Expected input/type: <em>true/false</em>. Enables automatic pruning of input columns based on different criteria such as amount of missing data, number of unique values, and standard deviation.<br />
<strong>Note</strong>:This automatically drops identifier columns (unique value for each sample) and columns that do not contain sufficient data to aid prediction.</p>
</li>
<li>
<p><em>max_int_uniques</em>: Expected input/type: <em>integer</em>. Threshold for automatic encoding of categorical variables. If a column contains at least <em>max_int_uniques</em> unique values, it is treated as categorical and one hot encoded during preprocessing.</p>
</li>
<li>
<p><em>max_unique_values</em>: Expected input/type: <em>integer</em>. Threshold for automatic pruning of categorical columns prior to one hot encoding based on the number of unique values.<br />
<strong>Note</strong>: If a categorical column contains at least <em>max_unique_values</em>, it is dropped during preprocessing prior to one hot encoding.</p>
</li>
<li>
<p><em>feature_eng</em>: Enables automatic feature generation. Identifies an appropriate time window and augments input with new features derived in the frequency and time domains.<br />
<strong>Note</strong>: Can only be applied to timeseries data. String aliases specify methods for window computation.</p>

<table border="1">
<thead>
<tr>
<th>ALIAS</th>
<th>DESCRIPTION</th>
</tr>
</thead>
<tbody>
<tr>
<td>None</td>
<td>No feature generation will be applied.</td>
</tr>
<tr>
<td>‘mi’</td>
<td>Uses mutual information to estimate the window length.</td>
</tr>
<tr>
<td>‘auc’</td>
<td>(<strong>Default</strong>) Uses autocorrelation to estimate the window length.</td>
</tr>
<tr>
<td>‘user’</td>
<td>User specified window length: see* window_len*.</td>
</tr>
</tbody>
</table>
</li>
<li>
<p><em>window_len</em>: Expected input/type: <em>integer</em>. User specified window length for feature generation.<br />
<strong>Note</strong>: This parameter is used only in the case that <em>user</em> is provided for the <em>feature_eng</em> parameter.</p>
</li>
<li>
<p><em>feature_select</em>: A number in [0,1] specifying the percentage of numerical features to maintain based on their dependency to the target. Ranks all features using mutual information and drops (1 - feature_select)% of the lowest-ranking features. <strong>Default is 1</strong> (keep all features).</p>
</li>
<li>
<p><em>outlier</em>: A string alias that indicates the outlier detection to apply during preprocessing.<br />
<strong>Note</strong>: Outliers are removed and later filled using imputation.</p>

<table border="1">
<thead>
<tr>
<th>ALIAS</th>
<th>DESCRIPTION</th>
</tr>
</thead>
<tbody>
<tr>
<td>None</td>
<td>(<strong>Default</strong>) No outlier detection will be applied.</td>
</tr>
<tr>
<td>‘mad’</td>
<td>Uses Median Absolute Deviation to detect outliers.</td>
</tr>
<tr>
<td>‘perc’</td>
<td>Uses Percentile-based outlier detection.</td>
</tr>
<tr>
<td>‘isol’</td>
<td>Uses an Isolation Forest to detect outliers.</td>
</tr>
</tbody>
</table>
</li>
<li>
<p><em>auto_save_per</em> (<em>supervised</em> only): Expected input/type: <em>integer</em>.  Sets the checkpoint frequency. The model creation progress is recorded after every <em>auto_save_per</em> generations.<br />
<strong>Note</strong>: If the model is retrained, the model begins from the last recorded checkpoint. The model is automatically saved at the end of evolution.</p>
</li>
<li>
<p><em>imbalance</em> (<em>supervised</em> only): Expected input/type: <em>true/false</em>. Enables automatic imbalance correction that selectively applies <em>random oversampling</em>, <em>random undersampling</em>, <em>synthetic minority oversampling</em> (SMOTE), or <em>adaptive synthetic sampling</em> (ADASYN) to the input data depending on problem characteristics.</p>
</li>
<li>
<p><em>n_clusters</em>(<em>unsupervised</em> only): Specifies the number of clusters to be used if <em>clustering</em> is enabled.<br />
<strong>Note</strong>: If this value is not provided, the number of clusters will be heuristically determined.</p>
</li>
<li>
<p><em>anomaly_prior</em> (<em>supervised</em> only): Expected input/type: *between [0,1]. *Significance level at which a point is defined as anomalous.<br />
<strong>Note</strong>: This parameter is used only for unsupervised problems if <em>clustering</em> is disabled.</p>
</li>
</ul>
<p><strong>Payload:</strong></p>
<div class="codebox">
<pre><code>{
  "target": "string",
  "dataset_names": ["dataset_name1"],
  "job_name": "my_job",
  "model_name": "string",
  "max_train_time": "00:01",
  "max_generation": 100,
  "recurrent": true,
  "impute": "mean",
  "drop": true,
  "max_int_uniques": 15,
  "max_unique_values": 50,
  "feature_eng": "mi",
  "feature_select": 1,
  "outlier": "mad",
  "auto_save_per": 10,
  "imbalance": true,
  "n_clusters": 5,
  "anomaly_prior": 0.01
}

</code></pre></div>
<p><strong>Response Codes</strong>: 201, 401, 403, 404, 408, 422</p>
<p><strong>Successful Response:</strong></p>
<div class="codebox">
<pre><code>{
    "job_name": "job_name1",
    "model_name": "model1_name",
}
</code></pre></div>
<hr />
<p><strong>Request Type:</strong> PATCH</p>
<p><strong>URI:</strong> /v1/train/model/{model_name}</p>
<p><strong>Headers:</strong></p>
<ul>
<li>Authorization: Bearer token</li>
</ul>
<p><strong>Description:</strong> Resume training for a model on the dataset identified by <em>dataset_name</em>.</p>
<p><strong>Parameter Descriptions:</strong>
<ul>
<li>target: String denoting target prediction column in input data.</li>
<li>dataset_names: A list of dataset names to use for training. <br /><strong>Note:</strong> only 1 is currently supported.</li>
<li>job_name: The job name</li>
<li>max_train_time: Sets the training time for the model in ‘HH:MM’ format. <br /><strong>Note:</strong> This overrides any values set for <em>max_generation</em></li>
</ul></p>

<p><strong>Payload:</strong></p>
<div class="codebox">
<pre><code>{
  "target": "string",
  "dataset_names": ["dataset_name1"],
  "job_name": "my_job",
  "max_train_time": "00:01"
}
</code></pre></div>
<p><strong>Response Codes:</strong> 201, 401, 403, 404, 408, 422</p>
<p><strong>Successful Response:</strong></p>
<div class="codebox">
<pre><code>{
    "job_name": "job_name1",
    "model_name": "model1_name",
}
</code></pre></div>
<hr />
<p><strong>Request Type:</strong> DELETE</p>
<p><strong>URI:</strong> /v1/train/model/{model_name}</p>
<p><strong>Headers:</strong></p>
<ul>
<li>Authorization: Bearer token</li>
</ul>
<p><strong>Description:</strong> Delete a model, possibly to prevent AI from becoming super<br />
intelligent and destroying the human race.</p>
<p><strong>Response Codes:</strong> 204, 401, 404, 422</p>
<p><strong>Successful Response:</strong> None</p>
<hr />
<h2><a name="uload">Upload</a></h2>
<p><strong>Request Type:</strong> POST</p>
<p><strong>URI:</strong> /v1/upload</p>
<p><strong>Headers:</strong></p>
<ul>
<li>Authorization: Bearer token</li>
</ul>
<p><strong>Description:</strong> Upload a dataset, model, or a figure.</p>
<p><strong>Form Data:</strong></p>
<ul>
<li>
<p><em>dataset</em>: a dataset file</p>
</li>
<li>
<p><em>dataset_name</em>: the name for the dataset</p>
</li>
</ul>
<p><strong>Response Codes:</strong> 201, 401, 403, 408, 413, 422</p>
<p><strong>Successful Response:</strong></p>
<div class="codebox">
<pre><code>{
    "dataset_name": "dataset1_name"
}
</code></pre></div>
<hr />
<p><strong>Request Type:</strong> DELETE</p>
<p><strong>URI:</strong> /v1/upload/{dataset_name}</p>
<p><strong>Headers:</strong></p>
<ul>
<li>Authorization: Bearer token</li>
</ul>
<p><strong>Description:</strong> Delete a dataset, model, or a figure.</p>
<p><strong>Response Codes:</strong> 204, 401, 404, 422</p>
<p><strong>Successful Response:</strong> None</p>
<hr />
<p><strong>Request Type:</strong> GET</p>
<p><strong>URI:</strong> /v1/download/{artifact_name}</p>
<p><strong>Headers:</strong></p>
<ul>
<li>Authorization: Bearer token</li>
</ul>
<p><strong>Description:</strong> Download an artifact.</p>
<p><strong>Response Codes:</strong> 200, 401, 404, 422</p>
<p><strong>Successful Response:</strong></p>
<div class="codebox">
<pre><code>{
    'artifact': 'some string'
}
</code></pre></div>
<hr />
<h1><a name="examp">Examples</a></h1>
<p>The following sections provide examples of how to use the Darwin API.</p>
<h2><a name="log">Login </a></h2>
<ol>
<li>Login using the <code>/v1/auth</code> routes. It is possible to login as either a <em>service</em> or a <em>user</em>.
<p>&nbsp;</p>
<table border="1">
<thead>
<tr>
<th>Login</th>
<th>Request</th>
</tr>
</thead>
<tbody>
<tr>
<td><a name="slogin">Login as service</a>:</td>
<td><strong>Request Type: POST</strong><br> <strong>URI</strong>: /v1/auth/login <br> <strong>Form Data</strong>: <br> <em>api_key</em>: The api key of the service <br> <em>pass1</em>: The service level password</td>
</tr>
<tr>
<td><a name="ulogin">Login as an end user</a>:</td>
<td><strong>Request Type: POST</strong> <br>  <strong>URI</strong>: /v1/auth/login/user <br> <strong>Form Data</strong>: <br>  <em>api_key</em>: The api key of the service <br> <em>username</em>: The end user name <br> <em>pass1</em>: The end user level password</td>
</tr>
</tbody>
</table>
<p>&nbsp;</p>
</li>

<li>Receive token. If login is successful, a response arrives with an access token. This token is used in the <em>authorization header</em> for other requests:
<pre>{
    'access_token': 'some_string'
}
</pre>
<p><em>Note:</em> The token (in this example “some string”) must be prepended with the string <code>Bearer</code>. <br />For example the token becomes:<br />
<code>Bearer MyNewTokenString</code> &nbsp; &nbsp; &nbsp; - 
(that is: <strong>Bearer(space)MyNewTokenString</strong>).</p>
</li>
</ol>
<h2><a name="supertrain">Train a model - supervised</a></h2>
<ol>
<li>Upload a dataset using the following:

<p><strong>Request Type</strong>: POST</p>
<p><strong>URI</strong>: /v1/upload</p>
<p><strong>Headers:</strong>
<ul><li>Authorization: Bearer token</li></ul>
</p>
<p><strong>Form Data</strong>:</p>
<ul>
<li><em>dataset</em>: a dataset file</li>
<li><em>dataset_name</em></li>
</ul>

<p><strong>Notes</strong>:</p>
<ul><li>Assign a name to the dataset. If no name is assigned, a random string is assigned in its place. It is necessary to keep track of lookup current datasets with the <code>/v1/lookup/dataset</code> route.</li>
<li>Ensure not to exceed upload limits. If the limits are exceeded, a <em>403 forbidden error</em> is generated. To fix the exceeded limit, delete a dataset that is older or no longer required.</li></ul>
</li>

<li>Set target parameter.<br />
Use the uploaded dataset to train a model. Specify the dataset name in the URI of the train route. Note that training a supervised model requires the <em>target</em> parameter is set:

<p><strong>Request Type</strong>: POST</p>
<p><strong>URI</strong>: /v1/train/model/{dataset_name}</p>
<p><strong>Headers:</strong>
<ul><li>Authorization: Bearer token</li></ul></p>

<p><strong>Payload</strong>:</p>
<div class="codebox">
<pre><code>{
  "target": "string",
  "dataset_names": ["dataset_name1"],
  "job_name": "job_name1",
  "model_name": "string",
  "max_train_time": "00:01",
  "max_generation": 100,
  "recurrent": true,
  "impute": "mean",
  "drop": true,
  "max_int_uniques": 15,
  "max_unique_values": 50,
  "feature_eng": "mi",
  "feature_select": 1,
  "outlier": "mad",
  "auto_save_per": 10,
  "imbalance": true,
  "clustering": true,
  "n_clusters": 5,
  "anomaly_prior": 0.01
}

</code></pre></div>
<p><strong>Note</strong>: Because many of the payload parameters are optional, depending on your use case, it is possible to use a simple payload, for example:</p>
<div class="codebox">
<pre><code>{
  "target": "string",
  "dataset_names": ["dataset_name1"]
}

</code></pre></div>
</li>
<li>Consult return.<br />
In response to the payload, a job name and model name are returned. Note that if the dataset was not named, a random string is returned as its name. For example:</li>

<div class="codebox">
<pre><code>{
    "job_name": "job_name1",
    "model_name": "model1_name",
}

</code></pre></div>
</li>
<li>Check job status.<br />
When the job name is returned, use the <code>/v1/job/status</code> or <code>/v1/job/status/{job_name}</code> route together with the job name to check the job status. For example:
<p><strong>Request Type</strong>: GET</p>
<p><strong>URI</strong>: /v1/job/status/{job_name}</p>
<p><strong>Headers:</strong></p>
<ul><li>Authorization: Bearer token</li></ul>
</p>
<p><strong>Query Parameters:</strong>
<ul>
<li>Age: List jobs that are less than <em>X</em> units old, for example, <em>3 weeks</em>, <em>2 days</em>.</li>
<li>Status: List job of a particular status, for example <em>Running</em>.</li></ul>
</p>


<p>The query return contains information about how far the job has progressed, as a percent_complete and status, the number of generations run (so far), and the model loss. For example:</p>
<div class="codebox">
<pre><code>{
        "status": "Requested",
        "percent_complete": 0,
        "loss": 0,
        "generations": 0,
        "dataset_names": [
            "phone_data"
        ]
        "model_name": "model1_name",
    }
</code></pre></div>
<p>When the job completes, the percent_complete shows <code>100</code> and status is set to <code>Complete</code>. The generated model can be used for additional tasks, described below.</p>
</li>
</ol>

<h2><a name="ustrain">Train a model - unsupervised</a></h2>
<p>The process to train an unsupervised model follows the same procedure as the supervised model training procedure. The difference is the target parameter in the <code>/v1/train/model/{dataset_name}</code> route is left unspecified. Depending on the use case, it is possible to simplify the payload to a set of empty braces:</p>
<div class="codebox">
<pre><code>    
	{}
</code></pre></div>
<h2><a name="crisk">Create risk data</a></h2>
<p>The following example shows how to generate risk data.</p>
<ol>
<li>Upload a failure dataset and time-series dataset through the /v1/upload route and follow the instructions above to create risk data. For example:
<p><strong>Request Type</strong>: POST</p>
<p><strong>URI</strong>: /v1/risk/{failure_data}/{timeseries_data}</p>
<p><strong>Headers:</strong>
<ul><li>Authorization: Bearer token</li></ul></p>


<p>Payload:</p>
<div class="codebox">
<pre><code>{
  "risk_columns": [
    "risk"
  ],
  "shutdown_column": "Shutdown Time",
  "return_column": "Return Time",
  "asset_column": "Asset",
  "lead_time": 1,
  "functional_form": "linear"
}
</code></pre></div>
</li>
<li>
<p>Consult the return. <br />The post action returns job and artifact names. The job name enables monitoring the job status.</p>
</li>
<li>
<p>Download the risk data.<br />
When the job completes, download the risk data via the <code>/v1/download/artifacts/{artifact_id}</code> route.</p>
</li>
</ol>
<h2><a name="adaset">Analyze a dataset</a></h2>
<ol>
<li>If necessary, upload a dataset using the instructions and the <code>/v1/upload</code> route.</li>
<li>Analyze the dataset through the <code>/v1/analyze/data/{dataset_name}</code> route:<
<p><strong>Request Type</strong>: POST</p>
<p><strong>URI</strong>: /v1/analyze/data/{dataset_name}</p>
<p><strong>Headers:</strong>
<ul><li>Authorization: Bearer token</li></ul></p>

<p>Payload:</p>
<div class="codebox">
<pre><code>{
  "target": "string",
  "impute": "mean",
  "drop": true,
  "max_int_uniques": 15,
  "max_unique_values": 50,
  "feature_eng": "mi",
  "feature_select": 1,
  "outlier": "mad"
}
</code></pre></div>
</li>
<li>
<p>Consult the return. <br />The post action returns job and artifact names. The job name enables monitoring the job status.</p>
</li>
<li>
<p>Download the analysis.<br />
When the job completes, download the data analysis with the <code>/v1/download/artifacts/{artifact_id}</code> route.</p>
</li>
</ol>
<h2><a name="anamodel">Analyze a model</a></h2>
<p>Analyze the trained model. 
<ol>
<li>Use the the <code>/v1/analyze/model/{model_name}</code> route:</p>
<p><strong>Request Type</strong>: POST</p>
<p><strong>URI</strong>: v1/analyze/model/{model_name}</p>
<p><strong>Headers:</strong>
<ul><li>Authorization: Bearer token</li></ul></p>
<p><strong>Form Data: </strong></p>
<ul>
<li><em>job_name</em>: The name of the job</li>
<li><em>artifact_name</em>: The name of the artifact</li>
</ul><br />
</li>
<li>Consult the return.<br /> The post action returns job and artifact names. The job name enables monitoring the job status.</li>
<li>Download the analysis.<br />
When the job completes, download the model analysis with the <code>/v1/download/artifacts/{artifact_name}</code> route.<br />
<strong>Note</strong>: The model analysis takes the form of a decoded PNG. You must encode this yourself (“latin-1” encoding) or you can use the provided Python SDK to retrieve the results automatically.</li>
</ol> <!--
<h2><a name="testmodel">Test a model</a></h2>
<p>It is possible to test the trained model on a separate dataset. To test the trained a model against a separate dataset:</p>
<ol>
<li>Upload the new dataset following previous instructions.</li>
<li>Test the model against the new data set through the <code>/v1/analyze/model/{model_name}</code> route:
<p><strong>Request Type</strong>: POST</p>
<p><strong>URI</strong>: /v1/analyze/model/{model_name}</p>
<p><strong>Headers:</strong>
<ul><li>Authorization: Bearer token</li></ul></p>
</li>
<li>Consult the return. The post action returns job and artifact names. The job name enables monitoring the job status.</li>
<li>Download the results.<br />
When the job completes, download the  the test results with the <code>/v1/download/artifacts/{artifact_id}</code> route.</li>
</ol>  -->
<h2><a name="umodel">Model uses</a></h2>
<p>A trained model and dataset can be used for prediction, classification, or for detecting data clusters and / or anomalies.<br />
After a model is trained, additional datasets can be uploaded and the model applied against those additional datasets. To perform these tasks:
<ol>
<li>
Use the <code>/v1/run/model/{model_name}/{dataset_name}</code> route:</p>
<p><strong>Request Type</strong>: POST</p>
<p><strong>URI</strong>: /v1/run/model/{model_name}/{dataset_name}</p>
<p><strong>Headers:</strong>
<ul><li>Authorization: Bearer token</li></ul></p>
</li>
<li>Consult the return.<br /> The post action returns job and artifact names. The job name enables monitoring the job status.</li>
<li>Download the results.<br />
When the job completes, download the results with the <code>/v1/download/artifacts/{artifact_id}</code> route.</li>
</ol>
<hr />
<h1><a name="reference">Reference</a></h1>
<hr />
<h2><a name="revision"></a>Revision Table</h2>

<table border="1">
<thead>
<tr>
<th>Version</th>
<th>Author</th>
<th>Date</th>
<th>Notes</th>
</tr>
</thead>
<tbody>
<tr>
<td>v 1.0</td>
<td>SparkCognition</td>
<td>02.02.2018</td>
<td>First Release</td>
</tr>
</tbody>
</table>


</body>
</html>
