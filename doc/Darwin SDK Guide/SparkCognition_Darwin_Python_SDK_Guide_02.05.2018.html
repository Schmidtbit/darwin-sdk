<!DOCTYPE html>
<html>
<head>
    <title>SparkCognition Darwin Python SDK Guide 02.05.2018</title>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
	<style>
		table, th, td {
			border: 1px solid black;
			}
		table {
			border-collapse:collapse;
			}
      .codebox {
        border: 1px solid black ;
        padding: 5px;
        width: 600px;
        Background-color: #EBF5FB;
      }
		hr.dbline {
		border-top: 3px double #8c8b8b;
		}
	</style>
</head>
<body>

<hr />
<img src="graphics/logo.png" width="60%">
<h1>Darwin<sup>&trade;</sup> Python SDK Manual</h1>
<h3>A SparkCognition<sup>&trade;</sup> Education Document</h3>
<h4>v. 1.0 - 02.05.2018</h4>
<hr />
<h1>Contents</h1>
<p>This document contains the following sections:</p>
<ul>
<li><a href="#about">About this guide</a>
	<ul><li><a href="#expect">Expectation</a></li>
	</ul>
</li>

<li><a href="#overview">Darwin overview</a>
	<ul>
	<li><a href="#getsdk">Setup Darwin SDK</a></li>
	<li><a href="#access">Accessing the API</a></li></ul>
	</li>
	</li>

<li><a href="#sdki">Darwin SDK interface</a>
	<ul><li><a href="#connect">Connect to the Darwin interface</a></li></ul>
	</li>
<li><a href="#methods">Darwin SDK methods</a>
<ul>
<li><a href="#gsmethods">URL Get/Set methods</a></li>
<li><a href="#authmethods">Authentication methods</a></li>
<li><a href="#jsmethods">Job status methods</a></li>
<li><a href="#lumethods">Lookup methods</a></li>
<li><a href="#damethods">Datasets and artifact methods</a></li>
<li><a href="#mamethods">Modeling and analysis methods</a></li>
<li><a href="#cmethods">Convenience methods</a></li>
</ul>
</li>
<li><a href="#reference">Reference</a>
<ul>
<li><a href="#example">SDK modeling example</a></li>
<li><a href="#sadataflow">SDK analyze data workflow example</a></li>
<li><a href="#revision">Revision table</a></li>
</ul>
</li>
</ul>
<hr class="dbline"/ >
<p>This document contains copyrighted and proprietary information of SparkCognition and is protected by United States copyright laws and international treaty provisions. No part of this publication may be reproduced, stored in a retrieval system or transmitted in any form or by any means, electronic, mechanical, photocopying, recording, scanning or otherwise, except as permitted under such laws or with the prior written permission of  SparkCognition Inc.</p>
<p>SparkCognition<sup>&trade;</sup>, the sparkcognition logo, Darwin<sup>&trade;</sup>, DeepArmor<sup>&reg;</sup>, DeepNLP<sup>&trade;</sup>, MindFabric<sup>&reg;</sup>, SparkSecure<sup>&reg;</sup> and SparkPredict<sup>&trade;</sup>, are trademarks of SparkCognition, Inc. and/or its affiliates and may not be used without written permission. All other trademarks are the property of their respective owners.</p>
<p>&copy;SparkCognition, Inc. 2018. All rights reserved.</p>
<hr / width="60%">
<h1 <a name="about">About this guide</a></h1>
<p>This manual describes using the Darwin™ SDK to access and use the Darwin API in automated model building. It is intended for data scientists, software engineers and analysts who want to use the Darwin API to interact with Darwin to create and train models, monitor jobs and perform analysis.The SDK also provides some convenience functions. Note that throughout this document, long key and token values are truncated, indicated by ellipses (<strong>…</strong>).</p>
<h2><a name="expect">Expectation</a></h1>
<p>This document assumes experience of the data scientist or software engineer that is commensurate with data science techniques and associated programming tasks.</p>
<h1><a name="overview">Darwin overview</a></h1>
<p>Darwin is a SparkCognition<sup>®</sup> tool that automates model building processes to solve specific problems. This tool enhances data scientist potential because it automates various tasks that are often manually performed. These tasks include data cleaning, latent relationship extraction, and optimal model determination. Darwin promotes rapid and accurate feature generation through both automated windowing and risk generation. Darwin quickly creates highly-accurate, dynamic models using both supervised and unsupervised learning methods.<br />
The general workflow for simple modeling includes:</p>
<ul>
<li>Upload training data</li>
<li>Create model</li>
<li>Upload test data</li>
<li>Test the model</li>
<li>Download result artifact</li>
</ul>
<p><strong>Note</strong>: Darwin expects all uploaded ingestion files to be in a <em>rectangular</em> format. This means a flat file with features that span columns and data samples that span rows. Plan your data file so it fits this expectation to help prevent errors.</p>
<p>See the <a href="#example">SDK example</a> for a modeling example.</p>
<p>For additional information on Darwin, contact your local SparkCognition partner for access to the white paper titled: <em>Darwin - A Neurogenesis Platform</em>.</p>
<h2><a name="access">Accessing the API</a></h2>
<p>This document describes the SDK and explains how to access the Darwin API and its functionality.<br />
Additional methods to access the Darwin API include:</p>
<ul>
<li>through the <code>https://darwin-api.sparkcognition.com/v1</code> end point</li>
<li>optionally, through user created <code>curl</code> commands</li>
</ul>
<p>For additional information on the Darwin API, contact your local SparkCognition partner for access to see the <em>SparkCognition Darwin API Guide</em>.</p>
<p><strong>Notes</strong>:
<ul>
<li>An <em>API key</em> is necessary to use the Darwin SDK. <br />Contact SparkCognition or your IT manager for an appropriate key.</li>
<li>All methods return a 2-tuple, for example:
</ul>
	  <div class="codebox">
<pre>    (True, &lt;context-dependent-return-object&gt;)
    (False, &lt;some-helpful-message&gt;)
</pre>
</div>
</p></li>
<h1><a name="sdki">Darwin SDK interface</a></h1>
<h2><a name="getsdk">Setup Darwin SDK</a></h2>
<p>Perform the following to download and setup the Darwin SDK:</p>
<ol>
<li>Install Python 3.5 or greater. Alternatively, install <em>Miniconda</em>, from <a href="https://conda.io/miniconda.html">https://conda.io/miniconda.html</a>.</li>
<li>Create a directory to receive the git repository clone.</li>
<li>Change (<em>cd</em>) into the new directory.</li>
<li>Clone the <em>darwin-sdk</em> repository:<br />
<pre><code>git clone https://github.com/sparkcognition/darwin-sdk</code></pre>
</li>
<li>Change into the new root directory of the <em>darwin-sdk</em> cloned darwin-sdk project:<br />
<code><pre>cd &lt;NewCloneRootDirectory&gt;</pre></code> <p><strong>Note</strong>: By default this is the <em>master</em> trunk . </p>
</li>
<li>Download the code: <br />
<pre><code>git pull</code></pre>
 </li>
<li>Setup the SDK: <br />
<pre><code>python setup.py install</code></pre>
<p>The SDK defaults to using the production URL: <a href="https://darwin-api.sparkcognition.com/v1/">https://darwin-api.sparkcognition.com/v1/</a> </p>
</li>
</ol>


<h2><a name="connect">Connect to the Darwin interface</a></h2>

<ol>
<li>Obtain an api key.
<p>To use the Darwin SDK, an API Key is required. A key can be obtained from SparkCognition support or your IT manager. An api_key is a long string, for example:
<div class="codebox" style="width: 630px;">
<pre><code>'RsJ74ZS5AvwznbHh0AfVSgrchhS9KxACDy3jefaQnxb9f6QTSDBFmhnGa0cOIWtNAIFRAG9ToOTpi0mnEo3zFA'</code></pre>
</div></p>
</li>
<li>Register the api key.
<p>The purpose of this method is to set a password for an api_key. Each api_key is synonymous with a service. This method must be invoked once for each api_key to establish a password for that key. </p>
<p><strong>Notes:</strong>
<ul>
<li>After successful registration, the service uses <code>auth_login()</code> to login as a service.</li>
<li>In version 1, the password cannot be changed.</li>
</ul>

 

<strong>Example</strong>
<div class="codebox">
<pre><code>
>>> from amb_sdk.sdk import DarwinSdk
>>> s = DarwinSdk()
>>> s.auth_register('asdf', 'iRgwut4kGs0ymULiuKtMd0WFvBYLMWSj16q2uysQeteqH9ssc+\
EETUvcysnPojRpfycLVHa2IlN1IlrfEk1YMA')
(True,'Bearer eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJleHAiOjE1MTU1MzM4NjEsImlh\
dCI6MTUxNTUzMDI2MS ... F56xZQiBT-89nrRz1nIXD5LfawHIj_MlUHQqM36vU')
</code></pre></div></p>
</li>
<li>Login. 
<p>Login as a <em>service</em> or <em>create a user</em> under the service and login as a user. 
<br />The following explains how to log in as a <em>service</em>. 
<p><strong>Notes:</strong>
<ul>
<li>Although <code>Bearer &lt;auth-token&gt;</code>, returned by <code>auth_login()</code>, is used in subsequent  calls to validate authenticity, it is not required for each method.</li>
<li> The SDK remembers the auth token for the DarwinSdk object. Although an auth token is currently valid for 1 hour, if the DarwinSdk object session life time exceeds 1 hour, the SDK will request another auth token until the session ends.</li>
</ul>

<strong>Example</strong>
<div class="codebox">
<pre><code>
>>> s.auth_login('asdf', 'iRgwut4kGs0ymULiuKtMd0WFvBYLMWSj16q2uysQeteqH9ssc+EET\
UvcysnPojRpfycLVHa2IlN1IlrfEk1YMA')
(True,'Bearer eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJleHAiOjE1MTU1MzQxNzIsImlh\
dCI6MTUxNTUzMD ... UQQfoXqYFKJSoRXXDNPE985-a08cE6_o')
</code></pre></div></p>

<p>When login (as a service) successfully completes, the SDK can be used to create and model a workflow.</p>

<p>Note, there are also <code>auth_register_user()</code> and <code>auth_login_user()</code> methods that allow you to create users and login as a specific user. You can choose to use the SDK as a service or create users underneath the service to partition datasets/models to be owned by specific users. It is more convenient to employ user accounts because the api_key is not necessary for logging in as a user.

<p><strong>Example</strong>
<div class="codebox">
<pre><code>
>>> s.auth_register_user('atestuser', 'apassword')
(True,
 'Bearer eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJqdGkiOiJkNjY0MmJjOC1iMmU5LTQxO\
DctODFlNS00YjI2MD ... 5zMp_1FfxU')
 
>>> s.auth_login_user('atestuser', 'apassword')
(True,
 'Bearer eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJqdGkiOiI3NGYzYmUxZS0yOTlmLTRhN\
zMtODU5ZC01NGRmM2F ... u1zGCeCONA')
</code></pre></div>
 </p></li>
 <li>Verify the connection.
<p>The default url in the SDK is <code>https://darwin-api.sparkcognition.com/v1/</code>. Use <code>get_url()</code> and <code>set_url()</code> to verify connection to the right Darwin service.</p>
</li></ol>

<hr />
<h1><a name="methods">Darwin SDK methods</a></h1>
<h2><a name="gsmethods">URL Get/Set methods</a></h2>
<p>DarwinSdk.<strong>get_url</strong>()</p>
<p>Get Darwin service url.</p>
<p><strong>Parameters</strong>: None</p>
<p><strong>Returns</strong>:</p>
<pre>    (True, &lt;url-string&gt;)
</pre>
<p><strong>Example</strong></p>
	  <div class="codebox">
<pre><code>In [10]: s.get_url()

Out[10]: (True, 'https://darwin-api.sparkcognition.com/v1/')
</code></pre>
  </div>
<hr />
<p>DarwinSdk.<strong>set_url</strong>(<em>url, version=‘v1’</em>)</p>
<p>Set Darwin service url and version.</p>
<p><strong>Parameters</strong>:</p>
<ul>
<li>
<p><strong>url</strong> - URL to the Darwin service</p>
</li>
<li>
<p><strong>version</strong> - (optional) defaults to ‘v1’</p>
</li>
</ul>
<p><strong>Returns</strong>:</p>
<pre><code>   (True, \url&gt;) or (False, 'invalid url')
</code> </pre>
<p><strong>Example</strong></p>
	  <div class="codebox">
<pre><code>In [9]: s.set_url('https://darwin-api.sparkcognition.com/v1/')

Out[9]: (True, 'https://darwin-api.sparkcognition.com/v1/')
</code></pre>
    </div>
</div>
<hr />
<h2><a name="authmethods">Authentication methods</a></h2>
<p>DarwinSdk.<strong>auth_register</strong>(<em>password, api_key</em>)</p>
<p>Register as a service. The purpose of this method is to set a password for an api_key. Each api_key is synonymous with a service. This method is invoked only once for each api_key to establish a password for that key. After registration, the service can use <em>auth_login</em>() to login as a service.<br />
<strong>Note</strong>: In version 1, the password cannot be changed.</p>
<p><strong>Parameters</strong>:</p>
<ul>
<li>
<p><em>password</em> - The service level password</p>
</li>
<li>
<p><em>api_key</em> - The api key for the service</p>
</li>
</ul>
<p><strong>Returns</strong>:</p>
<pre>    (True, 'Bearer &lt;auth-token&gt;') or (False, &lt;error-message&gt;)
</pre>
<p><code>Bearer &lt;auth-token&gt;</code> is used in subsequent  calls to validate authenticity.<br />
The SDK remembers the auth token for the AmkSdk object.<br />
<strong>Note</strong>: Although an auth token is currently valid for 1 hour, if the AmkSdk object session life time exceeds 1<br />
hour, the SDK will request another auth token until the session ends.</p>
<p><strong>Example</strong></p>
  <div class="codebox">
<pre><code>In [4]: s.auth_register('asdf', 'RsJ74ZS5AvwznbHh0AfVSgrchhS9KxACDy\
3jefaQnxb9f6QTSDBFmhnGa0cOIWtNAIFRAG9ToOTpi0mnEo3zFA')
Out[4]:
(True,
 'Bearer eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJleHAiO...iSdU8xlF4yJk')


</code></pre>
    </div>
<hr />
<p>DarwinSdk.<strong>auth_login</strong>(<em>password, api_key</em>)</p>
<p>Login as a service.<br />
<strong>Note</strong>: A service must have a password set using <em>auth_register()</em> to login successfully.</p>
<p><strong>Parameters:</strong></p>
<ul>
<li>
<p><em>password</em> - The service level password</p>
</li>
<li>
<p><em>api_key</em> - The api key for the service</p>
</li>
</ul>
<p><strong>Returns</strong>:</p>
<pre>    (True, 'Bearer &lt;auth-token&gt;') or (False, &lt;error-message&gt;)
</pre>
<p><code>Bearer \auth-token&gt;</code> is used in subsequent  calls to validate authenticity. The SDK remembers the auth token for the AmkSdk object.<br />
<strong>Note</strong>: Although an auth token is currently valid for 1 hour, if the AmkSdk object session life time exceeds the 1 hour limit, the SDK will acquire another auth token until the session ends.</p>
<p><strong>Example</strong></p>
<div class="codebox">
<pre><code>In [5]: s.auth_login('asdf',
'iRgwut4kGs0ymULiuKtMd0WFvBYLMWSj16q2uysQeteqH9ssc+EETUvcysnPojRpfyc\
LVHa2IlN1IlrfEk1YMA')

Out[5]:

(True,

'Bearer
eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJleHAiOjE1MTU1MzQxN....')

</code></pre>
</div>
<hr />
<p>DarwinSdk.<strong>auth_register_user</strong>(username, <em>password</em>)</p>
<p>Register a user. This method registers a new user.<br />
  <strong>Note:</strong>You must be logged in as a service to create a user.</p>
<p><strong>Parameters</strong>:</p>
<ul>
<li>
<p><em>username</em> - The new end user’s username</p>
</li>
<li>
<p><em>password</em> - new end user’s password</p>
</li>
</ul>
<p><strong>Returns</strong>:</p>
<pre>    (True, 'Bearer &lt;auth-token&gt;') or (False, &lt;error-message&gt;)
</pre>
<p><code>Bearer &lt;auth-token&gt;</code> is used in subsequent  calls to validate authenticity. The SDK remembers the auth token for the AmkSdk object.<br />
<strong>Note</strong>: Although an auth token is currently valid for 1 hour, if the AmkSdk object session life time exceeds the 1 hour limit, the SDK will acquire another auth token until the session ends.</p>
<p><strong>Example</strong></p>
<div class="codebox">
<pre><code>
In [8]: s.auth_register_user('user1', 'user1-password',
'iRgwut4kGs0ymULiuKtMd0WFvBYLMWSj16q2uysQeteqH9ssc+EETUvcysnPojRpfycLV\
Ha2IlN1IlrfEk1YMA')

Out[8]:

(True,

'Bearer
eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJleHAiOjE1MTU1MzQyN....')
</div>
</code></pre>
<hr />
<p>DarwinSdk.<strong>auth_login_user</strong>(<em>username, password</em>)</p>
<p>Login as a user. <br />
<strong>Note</strong>: A user must have a username and password set using <strong>auth_register_user</strong>() to successfully login.</p>
<p><strong>Parameters</strong>:</p>
<ul>
<li>
<p><em>username</em> - The end user’s username</p>
</li>
<li>
<p><em>password</em> - The service level password</p>
</li>
</ul>
<p><strong>Returns</strong>:</p>
<pre>    (True, 'Bearer &lt;auth-token&gt;') or (False, &lt;error-message&gt;)
</pre>
<p><code>Bearer &lt;auth-token&gt;</code> is used in subsequent  calls to validate authenticity. The SDK remembers the auth token for the AmkSdk object.<br />
<strong>Note</strong>: Although an auth token is currently valid for 1 hour, if the AmkSdk object session life time exceeds the 1 hour limit, the SDK will acquire another auth token until the session ends.</p>
<p><strong>Example</strong></p>
<div class="codebox">
<pre><code>
In [9]: s.auth_login_user('user1', 'user1-password',
'iRgwut4kGs0ymULiuKtMd0WFvBYLMWSj16q2uysQeteqH9ssc+EETUvcysnPojRpfycLV\
Ha2IlN1IlrfEk1YMA')

Out[9]:

(True,

'Bearer
eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJleHAiOjE1MTU1MzQzM....')

</code></pre>
</div>
<hr />
<h2><a name="jsmethods">Job status methods</a></h2>
<p>DarwinSdk.<strong>lookup_job_status</strong><em>(age=None, status=None)</em></p>
<p>Get status information for all jobs belonging to the current user or service.</p>
<p><strong>Parameters</strong>:
<ul>
	<li><em>age</em> - (optional) Filter jobs that are less than <em>X</em> units old, for example 3w, 2d, or 1h.</li>
	<li>
	Optional parameters: 
	
		<ul>
		<li><em>status</em> - If not specified, returns all jobs.</li>
		<li><em>running</em></li>
		<li><em>requested</em></li>
		<li><em>complete</em></li>
		<li><em>failed</em></li>
		</ul>
	
	</li>
</ul>
  </p>
<p><strong>Returns</strong>:</p>
<pre>    (True, &lt;list-of-jobs&gt;) or (False, &lt;error-message&gt;)
</pre>
<p><strong>Example</strong></p>
<div class="codebox">
<pre><code>
In [6]:  s.lookup_job_status(status='Complete')
Out[6]:
(True,
 [{'artifact_names': None,
   'dataset_names': ['cancer-train'],
   'endtime': '2018-02-01T10:53:50.451598',
   'generations': 0,
   'job_name': 'eeef500d629e4a2185eb8af6e18a83b4',
   'job_type': 'TrainModel',
   'loss': 2.0,
   'model_name': 'cancer-model',
   'percent_complete': 100,
   'starttime': '2018-02-01T10:52:42.280929',
   'status': 'Complete'}])
</code></pre>
</div>
<hr />
<p>DarwinSdk.<strong>lookup_job_status_name</strong>(<em>job_name</em>)</p>
<p>Get job status information for a job by <em>name</em>.</p>
<p><strong>Parameters</strong>:</p>
<ul>
<li><em>job_name</em> - The job name.</li>
</ul>
<p><strong>Returns</strong>:</p>
<pre>    (True, &lt;job-info&gt;) or (False, &lt;error-message&gt;)
</pre>
<p><strong>Example</strong></p>
<div class="codebox">
<pre><code>
In [19]: s.lookup_job_status_name('eeef500d629e4a2185eb8af6e18a83b4')
Out[19]:
(True,
 {'artifact_names': None,
  'dataset_names': ['cancer-train'],
  'endtime': None,
  'generations': 0,
  'job_type': 'TrainModel',
  'loss': None,
  'model_name': 'cancer-model',
  'percent_complete': 0,
  'starttime': '2018-02-01T10:52:42.280929',
  'status': 'Running'})
 
In [20]: s.lookup_job_status('Running')
</code></pre>
</div>
<hr />
<h3><a name="lumethods">Lookup methods</a></h3>
<p>DarwinSdk.<strong>lookup_artifact</strong>(<em>type=None</em>)</p>

<p>Get a list of artifacts belonging to the current user or service.</p>

<p><strong>Parameters</strong>:</p>

type - (optional) specifies the type of artifact. Values can be 'Model', 'Test', 'Dataset', 'Risk', 'Run'
<p><strong>Returns</strong>:

<pre>(True, &lt;job-info&gt;) or (False, &lt;error-message&gt;)</pre>
</p>
<p><strong>Example</strong>:</p>
<div class="codebox">
<pre><code>
In [30]: s.lookup_artifact('Run')
http://localhost:5000/v1/lookup/artifact
Out[30]:
(True,
 [{'created_at': '2018-02-01T11:09:55.731040',
   'id': 'b9a9205a-0772-11e8-a003-3b1c8766dad0',
   'mbytes': 0.0,
   'name': '8a63e21030d1483abb0f892963c1728f',
   'type': 'Run'},
  {'created_at': '2018-02-01T11:11:17.560360',
   'id': 'ea6f3f80-0772-11e8-9abe-77bc32e350c5',
   'mbytes': 0.0,
   'name': 'artifact-1',
   'type': 'Run'}]
</code></pre>
</div>  
  
<hr />
  
<p>DarwinSdk.<strong>lookup_artifact_name</strong>(<em>artifact_name</em>)</p>

<p>Get information for an artifact specified by its name.</p>

<p><strong>Parameters</strong>:</p>
<ul>
<li>artifact - specifies an artifact by its name</li>
</ul>
<p><strong>Returns</strong>:</p>

<pre>(True, &lt;job-info&gt;) or (False, &lt;error-message&gt;)</pre>

<p><strong>Example</strong>:</p>
<div class="codebox">
<pre><code>
In [31]: s.lookup_artifact_name('artifact-1')
Out[31]:
(True,
 {'created_at': '2018-02-01T11:11:17.560360',
  'mbytes': 0.0,
  'name': 'artifact-1',
  'type': 'Run'})
 </code></pre>
</div> 

<hr />
<p>DarwinSdk.<strong>lookup_client</strong>()</p>
<p>Get a client’s metadata. A client is the current user or service in context.</p>
<p><strong>Parameters</strong>: None</p>
<p><strong>Returns</strong>:</p>
<pre>    (True, &lt;client-info&gt;) or (False, &lt;error-message&gt;)
</pre>
<p><strong>Example</strong></p>
<div class="codebox">
<pre><code>
In [21]: s.lookup_client()
Out[21]:
(True,
 {'job_limit': None,
  'model_limit': None,
  'tier': 0,
  'upload_limit': None,
  'user_limit': None,
  'username': None})
</code></pre>
</div>
<hr />
<p>DarwinSdk.<strong>lookup_dataset</strong>()</p>
<p>Get the dataset(s) metadata for a user. The user is the current user or service in the current context. This is useful for listing all created datasets.</p>
<p><strong>Parameters</strong>: None</p>
<p><strong>Returns</strong>:</p>
<pre>    (True, &lt;list-of-dataset-info&gt;) or (False, &lt;error-message&gt;)
</pre>
<p><strong>Example</strong></p>
<div class="codebox">
<pre><code>
In [4]: s.lookup_dataset()
Out[4]:
(True,
 [{'categorical': None,
   'imbalanced': None,
   'mbytes': 0.02019977569580078,
   'name': 'unittest-cancer-dataset2',
   'sequential': None,
   'updated_at': '2018-01-31T15:37:28.310994'},
  {'categorical': None,
   'imbalanced': None,
   'mbytes': 0.02019977569580078,
   'name': 'cancer-train',
   'sequential': None,
   'updated_at': '2018-02-01T10:52:06.076279'}])
</code></pre>
</div>
<hr />
<p>DarwinSdk.<strong>lookup_dataset_name</strong>(<em>dataset_name</em>)</p>
<p>Get a specific dataset’s metadata.</p>
<p><strong>Parameters</strong>:</p>
<ul>
<li><em>dataset_name</em> - The name of the dataset. The name of a dataset is established in the <strong>upload_dataset</strong>() method.</li>
</ul>
<p><strong>Returns</strong>:</p>
<pre>    (True, &lt;dataset-info&gt;) or (False, &lt;error-message&gt;)
</pre>
<p><strong>Example</strong></p>
<div class="codebox">
<pre><code>
In [36]: s.lookup_dataset_name('cancer-train')
Out[36]:
(True,
 {'categorical': None,
  'imbalanced': None,
  'mbytes': 0.02019977569580078,
  'sequential': None,
  'updated_at': '2018-02-01T10:52:06.076279'})
</code></pre>
</div>
<hr />
<p>DarwinSdk.<strong>lookup_model</strong>()</p>
<p>Get the model(s) metadata for a user. The user is the current user or service in the current context. This is useful for listing all models.</p>
<p><strong>Parameters</strong>: None</p>
<p><strong>Returns</strong>:</p>
<pre>    (True, &lt;list-of-model-info&gt;) or (False, &lt;error-message&gt;)
</pre>
<p><strong>Example</strong></p>
<div class="codebox">
<pre><code>
In [37]: s.lookup_model()
Out[37]:
(True,
 [{'generations': 0,
   'loss': 2.0,
   'name': 'cancer-model',
   'parameters': {'target': 'Diagnosis'},
   'trained_on': ['cancer-train'],
   'updated_at': '2018-02-01T10:53:50.443166'}])
</code></pre>
</div>
<hr />
<p>DarwinSdk.<strong>lookup_model_name</strong>(<em>model_name</em>)</p>
<p>Get a specific model’s metadata. The name of a model is established in the <em>create_model()</em> method.</p>
<p><strong>Parameters</strong>:</p>
<ul>
<li><em>model_name</em> - The name of the model</li>
</ul>
<p><strong>Returns</strong>:</p>
<pre>    (True, &lt;model-info&gt;) or (False, &lt;error-message&gt;)
</pre>
<p><strong>Example</strong></p>
<div class="codebox">
<pre><code>
In [40]: s.lookup_model_name('cancer-model')
Out[40]:
(True,
 {'generations': 0,
  'loss': 2.0,
  'parameters': {'target': 'Diagnosis'},
  'trained_on': ['cancer-train'],
  'updated_at': '2018-02-01T10:53:50.443166'})
</code></pre>
</div>
<hr />
<p>DarwinSdk.<strong>lookup_tier</strong>()</p>
<p>Get metadata for all tiers. A tier specifies certain usage limits such as <em>number of models</em> and <em>datasets</em>.</p>
<p><strong>Parameters</strong>: None</p>
<p><strong>Returns</strong>:</p>
<pre>    (True, &lt;list-of-tier-info&gt;) or (False, &lt;error-message&gt;)
</pre>
<p><strong>Example</strong></p>
<div class="codebox">
<pre><code>
In [41]: s.lookup_tier()
Out[41]:
(True,
 [{'job_limit': None,
   'model_limit': None,
   'tier': 0,
   'upload_limit': None,
   'user_limit': None},
  {'job_limit': 10000,
   'model_limit': 10000,
   'tier': 1,
   'upload_limit': 10000,
   'user_limit': 1000}])
</code></pre>
</div>
<hr />
<p>DarwinSdk.<strong>lookup_tier_num</strong>(<em>tier_num</em>)</p>
<p>Get a specific tier’s metadata. A tier specifies certain usage limits such as the <em>number of models</em> or <em>datasets</em>.</p>
<p><strong>Parameters</strong>:</p>
<ul>
<li><em>tier_num</em> - The name of the model</li>
</ul>
<p><strong>Returns</strong>:</p>
<pre>    (True, &lt;tier-info&gt;) or (False, &lt;error-message&gt;)
</pre>
<p><strong>Example</strong></p>
<div class="codebox">
<pre><code>
In [44]: s.lookup_tier_num(1)
Out[44]:
(True,
 {'job_limit': 10000,
  'model_limit': 10000,
  'tier': 1,
  'upload_limit': 10000,
  'user_limit': 1000})
</code></pre>
</div>
<hr />
<h2><a name="damethods">Datasets and artifact methods</a></h2>
<p>DarwinSdk.<strong>upload_dataset</strong>(<em>dataset</em>, <em>dataset_name=None</em>)</p>
<p>Upload a dataset, model, or a figure.</p>
<p><strong>Parameters</strong>:</p>
<ul>
<li>
<p><em>dataset</em>- Path to dataset</p>
</li>
<li>
<p><em>dataset_name</em> - Name to be given to dataset, or defaults to filename</p>
</li>
</ul>
<p><strong>Returns</strong>:</p>
<pre>    (True, {dataset_name:&lt;name-given-to-dataset&gt;})  or (False, &lt;error-message&gt;)
</pre>
<p><strong>Example</strong></p>
<div class="codebox">
<pre><code>
In [5]: s.upload_dataset('sets/cancer_train.csv', 'unittest-cancer-dataset')
Out[5]:
(True,
 {'dataset_name': 'unittest-cancer-dataset'})

</code></pre>
</div>
<hr />
<p>DarwinSdk.<strong>delete_dataset</strong>(<em>dataset_name</em>)</p>
<p>Delete the named dataset.</p>
<p><strong>Parameters</strong>:</p>
<ul>
<li><em>dataset_name</em> - The name of the dataset to be deleted.</li>
</ul>
<p><strong>Returns</strong>:</p>
<pre>    (True, None)  or (False, &lt;error-message&gt;)
</pre>
<p><strong>Example</strong></p>
<div class="codebox">
<pre>In [6]: s.delete_dataset('unittest-cancer-dataset')
Out[6]:
(True, None)
</pre>
</div>
<hr />
<p>DarwinSdk.<strong>download_artifact</strong>(<em>artifact_name</em>)</p>
<p>Download artifact given its name. The methods that return artifacts are:</p>
<ul>
<li><em>analyze_data()</em></li>
<li><em>analyze_model()</em></li>
<li><em>run_model(</em>)</li>
<li><em>create_risk_info()</em> <br />
<strong>Note</strong>: The artifact for <em>analyze_model()</em> is a png file.</li>
</ul>
<p><strong>Parameters</strong>:</p>
<ul>
<li><em>artifact_name</em> - The name of the artifact to download.</li>
</ul>
<p><strong>Returns</strong>:</p>
<pre>    (True, &lt;path-to-file&gt;) or (True, &lt;python-list&gt;) or (False, &lt;error-message&gt;)
</pre>
<p><strong>Example <em>run_model()</em> or prediction artifact</strong></p>
<div class="codebox">
<pre><code>
In [8]: s.download_artifact('4c4b0833fc1b4edeb689cba86c94a58d')                                                                                                   
Out[8]:     
Out[8]:     
(True,
	['Diagnosis', 
	'BENIGN',
	'BENIGN',
	'BENIGN',
	'BENIGN',
	'MALIGNANT',
	...
	]
)
</code></pre>
</div>

<p><strong>Example <em>analyze_data()</em> artifact</strong></p>
<div class="codebox">
<pre><code>
 In [17]: c, r = s.download_artifact('03676cb98d5b48fc89b2d058022781d8')
 
In [18]: print(r)
  categories      col_name     col_type      max     mean       min  \
0       None  mean_profile    numerical  180.219  95.3869    5.8125  
1       None   std_profile    numerical  91.8086  44.3984    24.772  
2       None  kurt_profile    numerical  8.06952  1.24083  -1.60483  
3       None  skew_profile    numerical  68.1016  5.72565  -1.78189  
4       None    mean_dmsnr    numerical  222.421   23.786  0.273411  
5       None     std_dmsnr    numerical  110.642   35.272   7.56568  
6       None    kurt_dmsnr    numerical  32.1986  6.66098  -3.13927  
7       None    skew_dmsnr    numerical  1072.96  79.4015  -1.97698  
8        0,1         class  categorical     None     None      None  
 
   num_categories      std 
0          3939.0  36.4588 
1          4635.0  8.03585 
2          4639.0  1.80623 
3          4639.0  11.0723 
4          4012.0  39.2822 
5          4639.0  23.9892 
6          4639.0  4.87737 
7          4639.0   103.01 
8             2.0     None
</code></pre>
</div>


<p><strong>Example <em>analyze_model()</em> or prediction artifact</strong></p>
<div class="codebox">
<pre><code>
  In [5]: s.download_artifact('6e4861de29424cb7ad09e467d1869c17')
  Out[5]:
  (True,
   {'filename': '/var/folders/9r/_wwbjsd17_5b74dww69mtg9h0000gp/T/artifact-\
   0nq69erf.png'})
</pre>
</code></div>

<p><strong>Example <em>create_risk_info()</em> artifact</strong></p>
<div class="codebox">
<pre><code>
  In [5]: s.download_artifact('6ec2c1bc6c1244ccb3b03f25ebac5850')
  Out[5]:
  (True,
   {'filename': '/var/folders/9r/_wwbjsd17_5b74dww69mtg9h0000gp/T/tmp\
   jawjkj4f'})

  $ head tmpjawjkj4f
  risk
  0.0
  0.0
  1.0
  0.0
  1.0
</code></pre>
</div>
<hr />
<p>DarwinSdk.<strong>delete_artifact</strong>(<em>artifact_name</em>)</p>
<p>Delete the artifact given its name.</p>
<p><strong>Parameters</strong>:</p>
<ul>
<li><em>artifact_name</em> - The <em>name</em> of the artifact to be deleted.</li>
</ul>
<p><strong>Returns</strong>:</p>
<pre>    (True, None)  or (False, &lt;error-message&gt;)
</pre>
<p><strong>Example</strong></p>
<div class="codebox">
<pre><code>
In [8]: s.delete_artifact('6c482eac9f894cdb9b0e1e487e41730a')
Out[8]:
(True, None)
</code></pre>
</div>
<h2><a name="mamethods">Modeling and analysis methods</a></h2>
<p>DarwinSdk.<strong>create_model</strong>(<em>dataset_names, **kwargs</em>)</p>
<p>Create a model trained on the dataset identified by dataset_name. The name of a model is specified in a parameter in kwargs.<br />
<strong>Note</strong>: If no name is specified, the model is named with a <em>uuid-like</em> name.</p>
<p><strong>Parameters</strong>:</p>
<ul>
<li>
<p><em>dataset_names</em> - A single dataset name as a string or a list of dataset string names to be used for training</p>
</li>
<li>**<em>kwargs</em> - variable number of keyword arguments, described in <em>parameters</em>.</li>
<li>
<p><em>parameters</em> - 

	<ul>
		<li>
		<p><em>model_name</em>: The string identifier of the model to be trained. If no name is specified, the model is named with a <em>uuid-like</em> name.</p>
		</li>
		<li><em>job_name</em>: If no name is specified, the job is named with a <em>uuid-like</em> name.</p></li>
		<li>
		<p><em>target</em>: String denoting target prediction column in input data.</p>
		</li>
		<li><em>Model_name</em>: The string identifier of the model to be trained.</li>
		<li>
		<p><em>max_train_time</em>: Sets the training time for the model in ‘HH:MM’ format.<br />
		<strong>Note</strong>: This overrides any values set for <em>max_generation</em>.</p>
		</li>
		<li>
		<p><em>max_generation</em>: Expected input/type: <em>numeric</em>. Sets the training time for the model in generations. If <em>max_train_time</em> is set, this parameter is ignored.</p>
		</li>
		<li>
		<p><em>recurrent</em>: Expected input/type: <em>true/false</em>. Enables recurrent connections to be evolved in the model. This option can be useful for timeseries or sequential data.<br />
		<strong>Note</strong>:  This option is automatically enabled if a <em>datetime</em> column is detected in the input data. This can result in slower model evolution.</p>
		</li>
		<li>
		<p><em>impute</em>: String alias that indicates how to fill in missing values in input data.</p>
		
		<table border="1">
			<col style="width:10%">
			<col style="width:70%">
			<col style="width:20%">
		<thead>
		<tr>
		<th>ALIAS</th>
		<th>DESCRIPTION</th>
		<th>COMPLEXITY</th>
		</tr>
		</thead>
		<tbody>
		<tr>
		<td>‘genetic’</td>
		<td>Genetic Fill: Automatically determines the most appropriate fast imputation method using evolutionary methods.</td>
		<td>Linear</td>
		</tr>
		<tr>
		<td>‘ffill’</td>
		<td>(Default) Forward Fill: Propagate values forward from one example into the missing cell of the next example. Might be useful for timeseries data, but also applicable for both numerical and categorical data.</td>
		<td>Linear <br> Fast</td>
		</tr>
		<tr>
		<td>‘bfill’</td>
		<td>Backward Fill: Propagate values backward from one example into the missing cell of the previous example. Might be useful for timeseries data, but also applicable for both numerical and categorical data.</td>
		<td>Linear <br> Fast</td>
		</tr>
		<tr>
		<td>‘mean’</td>
		<td>Mean Fill: Computes the mean value of all non-missing examples in a column to fill in missing examples. The result may or might not be interpretable in terms of the input space for categorical variables.</td>
		<td>Linear <br> Fast</td>
		</tr>
		<tr>
		<td>‘median’</td>
		<td>Median Fill: Computes the median value of all non-missing examples in a column to fill in missing examples. While the result is interpretable in terms of the input space for categorical variables, the approach might not be appropriate for non-ordinal data.</td>
		<td>Linear <br> Fast</td>
		</tr>
		<tr>
		<td>‘mode’</td>
		<td>Mode Fill: Uses the most common value on a column-by-column basis to fill in missing examples. The result is interpretable for both numerical and categorical variables.</td>
		<td>Linear <br> Fast</td>
		</tr>
		<tr>
		<td>‘spline’</td>
		<td>Spline Fill: Interpolation using a spline (piecewise function). Might be useful for timeseries or sequential data.</td>
		<td>Linear <br> Fast</td>
		</tr>
		<tr>
		<td>‘Linear’</td>
		<td>Linear Interpolation Fill: Interpolation using a Linear function. Might be useful for timeseries or sequential data.</td>
		<td>Linear <br> Fast</td>
		</tr>
		<tr>
		<td>‘knn’</td>
		<td>K-Nearest Neighbors Fill: Fills in missing values by averaging the cell values of the k nearest neighbors in the reduced feature space defined by all non-missing columns.</td>
		<td>Polynomial <br> Slow</td>
		</tr>
		<tr>
		<td>‘rmf’</td>
		<td>Robust Matrix Factorization Fill: Computes low-rank matrices L (observations x rank), R (features x rank), and E where X is input data, and X = LR<sup>T</sup> + E.</td>
		<td>Polynomial <br>Slow</td>
		</tr>
		<tr>
		<td>‘mice’</td>
		<td>Multiple Imputation by Chained Equations: First imputes missing values using <em>Forward Fill</em>. Then, column-by-column, missing values are reintroduced and regressed upon using the other (non-missing) columns. Continues iteratively.</td>
		<td>Polynomial, Iterative <br>Very Slow</td>
		</tr>
		</tbody>
		</table>
		</li>
		<li>
<p><em>drop</em>: Expected input/type: <em>true/false</em>. Enables automatic pruning of input columns based on different criteria such as amount of missing data, number of unique values, and standard deviation.<br />
<strong>Note</strong>:This automatically drops identifier columns (unique value for each sample) and columns that do not contain sufficient data to aid prediction.</p>
</li>
<li>
<p><em>max_int_uniques</em>: Expected input/type: <em>integer</em>. Threshold for automatic encoding of categorical variables. If a column contains at least <em>max_int_uniques</em> unique values, it is treated as categorical and one hot encoded during preprocessing.</p>
</li>
<li>
<p><em>max_unique_values</em>: Expected input/type: <em>integer</em>. Threshold for automatic pruning of categorical columns prior to one hot encoding based on the number of unique values.<br />
<strong>Note</strong>: If a categorical column contains at least <em>max_unique_values</em>, it is dropped during preprocessing prior to one hot encoding.</p>
</li>
<li>
<p><em>feature_eng</em>: Enables automatic feature generation. Identifies an appropriate time window and augments input with new features derived in the frequency and time domains.<br />
<strong>Note</strong>: Can only be applied to timeseries data. String aliases specify methods for window computation.</p>

<table border="1">
<thead>
<tr>
<th>ALIAS</th>
<th>DESCRIPTION</th>
</tr>
</thead>
<tbody>
<tr>
<td>None</td>
<td>No feature generation will be applied.</td>
</tr>
<tr>
<td>‘mi’</td>
<td>Uses mutual information to estimate the window length.</td>
</tr>
<tr>
<td>‘auc’</td>
<td>(<strong>Default</strong>) Uses autocorrelation to estimate the window length.</td>
</tr>
<tr>
<td>‘user’</td>
<td>User specified window length: see* window_len*.</td>
</tr>
</tbody>
</table>
</li>
<li>
<p><em>window_len</em>: Expected input/type: <em>integer</em>. User specified window length for feature generation.<br />
<strong>Note</strong>: This parameter is used only in the case that <em>user</em> is provided for the <em>feature_eng</em> parameter.</p>
</li>
<li>
<p><em>feature_select</em>: A number in [0,1] specifying the percentage of numerical features to maintain based on their dependency to the target. Ranks all features using mutual information and drops (1 - feature_select)% of the lowest-ranking features. Default is <strong>1</strong> (keep all features).</p>
</li>
<li>
<p><em>outlier</em>: A string alias that indicates the outlier detection to apply during preprocessing.<br />
<strong>Note</strong>: Outliers are removed and later filled using imputation.</p>

<table border="1">
<thead>
<tr>
<th>ALIAS</th>
<th>DESCRIPTION</th>
</tr>
</thead>
<tbody>
<tr>
<td>None</td>
<td>(<strong>Default</strong>) No outlier detection will be applied.</td>
</tr>
<tr>
<td>‘mad’</td>
<td>Uses Median Absolute Deviation to detect outliers.</td>
</tr>
<tr>
<td>‘perc’</td>
<td>Uses Percentile-based outlier detection.</td>
</tr>
<tr>
<td>‘isol’</td>
<td>Uses an Isolation Forest to detect outliers.</td>
</tr>
</tbody>
</table>
</li>
<li>
<p><em>auto_save_per</em> (supervised only): Expected input/type: <em>integer</em>.  Sets the checkpoint frequency. The model creation progress is recorded after every auto_save_per generations.<br />
<strong>Note</strong>: If the model is retrained, the model begins from the last recorded checkpoint. The model is automatically saved at the end of evolution.</p>
</li>
<li>
<p><em>imbalance</em> (supervised only): Expected input/type: <em>true/false</em>. Enables automatic imbalance correction that selectively applies random oversampling, random undersampling, synthetic minority oversampling (SMOTE), or adaptive synthetic sampling (ADASYN) to the input data depending on problem characteristics.</p>
</li>
<li>
<p><em>clustering</em>: Expected input/type: <em>true/false</em>. Enables clustering for unsupervised problems. If false, detects outliers.</p>
</li>
<li>
<p><em>n_clusters</em>: Expected input/type: <em>integer</em>. Specifies the number of clusters to be used if clustering is enabled.<br />
<strong>Note</strong>: If this value is not provided, the number of clusters will be heuristically determined.</p>
</li>
<li>
<p><em>anomaly_prior</em>: Expected input/type: *between [0,1]. *Significance level at which a point is defined as anomalous.<br />
<strong>Note</strong>: This parameter is used only for unsupervised problems if clustering is disabled.</p>
</li>
</ul>
<p><strong>Returns</strong>:</p>
<pre>    (True, {'job_id': &lt;uuid1&gt;, model_name: &lt;model_name&gt;}) or (False, &lt;error-message&gt;)
</pre>
<p><strong>Example</strong></p>
<div class="codebox">
<pre><code>
In [10]: s.create_model('cancer-data', target="Diagnosis", model_name="cancer-\
model", max_train_time="00:01", max_generation=100)
Out[10]:
(True,
 {'job_id': 'f5124576a4f34e5c9ab3499770455509',
  'model_name': 'cancer-model'})

</code></pre>
</div>
<hr />
<p>DarwinSdk.<strong>delete_model</strong>(<em>model_name</em>)</p>
<p>Delete a model named by <em>model_name</em>.</p>
<p><strong>Parameters</strong>:</p>
<ul>
<li><em>model_name</em> - Name of the model to be deleted.</li>
</ul>
<p><strong>Returns</strong>:</p>
<pre>    (True, None) or (False, &lt;error-message&gt;)
</pre>
<p><strong>Example</strong></p>
<div class="codebox">
<pre><code>
In [5]: s.delete_model('unittest-cancer-model')
Out[5]: (True, None)

</code></pre>
</div>
<hr />
<p>DarwinSdk.<strong>resume_training_model</strong>(<em>model_name, dataset_names, **kwargs</em>)</p>
<p>Resume training for a model on the dataset(s) identified by <em>dataset_names</em>.</p>
<p><strong>Parameters</strong>:</p>
<ul>
<li>
<p><em>dataset_name</em>- Name of dataset(s) used to train.</p>
</li>
<li>
<p><em>model_name</em> - Name of the model to train.</p>
</li>
<li>
<p>**<em>kwargs</em> -  variable number of keyword arguments, described below:</em>. 
		<ul>
		<li><em>job_name</em> - If not specified, a uuid is created as the <em>job_name</em>.</li>
		<li><em>max_train_time</em> - If not specified, the <em>default</em> is used.</li>
		</ul>
</li>
</ul>

<p><strong>Returns</strong>:</p>
<pre>    (True, { "job_id""&lt;uuid&gt;", "model_name": "&lt;model_name&gt;" })  or (False, &lt;error-message&gt;)
</pre>
<p><strong>Example</strong></p>
<div class="codebox">
<pre><code>
In [8]: s.resume_training_model('unittest-cancer-model', 'unittest-cancer-\
dataset',  target="Diagnosis", max_train_time="00:01")
Out[8]:
(True, {"job_id": "4e59ffc425e047e1a3b872f1e7396976", "model_name": "unittest-\
cancer-model"})
</code></pre>
</div>
<hr />
<p>DarwinSdk.<strong>analyze_data</strong>(<em>dataset_name, **kwargs</em>)</p>
<p>Analyze the dataset given its <em>name</em>.</p>
<p><strong>Parameters</strong>:</p>
<ul>
<li><em>dataset_name</em> - The name of the dataset to be analyzed.</li>

<li>**<em>kwargs</em> - variable number of keyword arguments, described below:</em>

	<ul>
		<li><em>job_name</em> - (optional) If not specified, a uuid will be created as the job_name.</li>
		<li><em>artifact_name</em>: (optional) If not specified, a uuid will be created as the <em>artifact_name</em>.</li>
		<li><em>target</em>: String denoting target prediction column in input data.</li>
		<li>
		<em>impute</em>: String alias that indicates how to fill in missing values in input data.
		
		<table border="1">
			<col style="width:10%">
			<col style="width:70%">
			<col style="width:20%">
		<thead>
		<tr>
		<th>ALIAS</th>
		<th>DESCRIPTION</th>
		<th>COMPLEXITY</th>
		</tr>
		</thead>
		<tbody>
		<tr>
		<td>‘genetic’</td>
		<td>Genetic Fill: Automatically determines the most appropriate fast imputation method using evolutionary methods.</td>
		<td>Linear</td>
		</tr>
		<tr>
		<td>‘ffill’</td>
		<td><strong>(Default)</strong> Forward Fill: Propagate values forward from one example into the missing cell of the next example. Might be useful for timeseries data, but also applicable for both numerical and categorical data.</td>
		<td>Linear <br> Fast</td>
		</tr>
		<tr>
		<td>‘bfill’</td>
		<td>Backward Fill: Propagate values backward from one example into the missing cell of the previous example. Might be useful for timeseries data, but also applicable for both numerical and categorical data.</td>
		<td>Linear <br> Fast</td>
		</tr>
		<tr>
		<td>‘mean’</td>
		<td>Mean Fill: Computes the mean value of all non-missing examples in a column to fill in missing examples. The result may or might not be interpretable in terms of the input space for categorical variables.</td>
		<td>Linear <br> Fast</td>
		</tr>
		<tr>
		<td>‘median’</td>
		<td>Median Fill: Computes the median value of all non-missing examples in a column to fill in missing examples. While the result is interpretable in terms of the input space for categorical variables, the approach might not be appropriate for non-ordinal data.</td>
		<td>Linear <br> Fast</td>
		</tr>
		<tr>
		<td>‘mode’</td>
		<td>Mode Fill: Uses the most common value on a column-by-column basis to fill in missing examples. The result is interpretable for both numerical and categorical variables.</td>
		<td>Linear <br> Fast</td>
		</tr>
		<tr>
		<td>‘spline’</td>
		<td>Spline Fill: Interpolation using a spline (piecewise function). Might be useful for timeseries or sequential data.</td>
		<td>Linear <br> Fast</td>
		</tr>
		<tr>
		<td>‘Linear’</td>
		<td>Linear Interpolation Fill: Interpolation using a Linear function. Might be useful for timeseries or sequential data.</td>
		<td>Linear <br> Fast</td>
		</tr>
		<tr>
		<td>‘knn’</td>
		<td>K-Nearest Neighbors Fill: Fills in missing values by averaging the cell values of the k nearest neighbors in the reduced feature space defined by all non-missing columns.</td>
		<td>Polynomial <br> Slow</td>
		</tr>
		<tr>
		<td>‘rmf’</td>
		<td>Robust Matrix Factorization Fill: Computes low-rank matrices L (observations x rank), R (features x rank), and E where X is input data, and X = LR<sup>T</sup> + E.</td>
		<td>Polynomial <br>Slow</td>
		</tr>
		<tr>
		<td>‘mice’</td>
		<td>Multiple Imputation by Chained Equations: First imputes missing values using <em>Forward Fill</em>. Then, column-by-column, missing values are reintroduced and regressed upon using the other (non-missing) columns. Continues iteratively.</td>
		<td>Polynomial, Iterative <br>Very Slow</td>
		</tr>
		</tbody>
		</table>
		</li>
		<li>
<p><em>drop</em>: Expected input/type: <em>true/false</em>. Enables automatic pruning of input columns based on different criteria such as amount of missing data, number of unique values, and standard deviation.<br />
<strong>Note</strong>:This automatically drops identifier columns (unique value for each sample) and columns that do not contain sufficient data to aid prediction.</p>
</li>
<li>
<p><em>max_int_uniques</em>: Expected input/type: <em>integer</em>. Threshold for automatic encoding of categorical variables. If a column contains at least <em>max_int_uniques</em> unique values, it is treated as categorical and one hot encoded during preprocessing.</p>
</li>
<li>
<p><em>max_unique_values</em>: Expected input/type: <em>integer</em>. Threshold for automatic pruning of categorical columns prior to one hot encoding based on the number of unique values.<br />
<strong>Note</strong>: If a categorical column contains at least <em>max_unique_values</em>, it is dropped during preprocessing prior to one hot encoding.</p>
</li>
<li>
<p><em>feature_eng</em>: Enables automatic feature generation. Identifies an appropriate time window and augments input with new features derived in the frequency and time domains.<br />
<strong>Note</strong>: Can only be applied to timeseries data. String aliases specify methods for window computation.</p>

<table border="1">
<thead>
<tr>
<th>ALIAS</th>
<th>DESCRIPTION</th>
</tr>
</thead>
<tbody>
<tr>
<td>None</td>
<td>No feature generation will be applied.</td>
</tr>
<tr>
<td>‘mi’</td>
<td>Uses mutual information to estimate the window length.</td>
</tr>
<tr>
<td>‘auc’</td>
<td>(<strong>Default</strong>) Uses autocorrelation to estimate the window length.</td>
</tr>
<tr>
<td>‘user’</td>
<td>User specified window length: see* window_len*.</td>
</tr>
</tbody>
</table>
</li>
<li>
<p><em>window_len</em>: Expected input/type: <em>integer</em>. User specified window length for feature generation.<br />
<strong>Note</strong>: This parameter is used only in the case that <em>user</em> is provided for the <em>feature_eng</em> parameter.</p>
</li>
<li>
<p><em>feature_select</em>: A number in [0,1] specifying the percentage of numerical features to maintain based on their dependency to the target. Ranks all features using mutual information and drops (1 - feature_select)% of the lowest-ranking features. Default is <strong>1</strong> (keep all features).</p>
</li>
<li>
<p><em>outlier</em>: A string alias that indicates the outlier detection to apply during preprocessing.<br />
<strong>Note</strong>: Outliers are removed and later filled using imputation.</p>
</li>
</ul>
<p><strong>Returns</strong>:</p>
<pre><code>    (True, {"job_name”: &lt;string&gt;, "artifact_name”: &lt;string&gt;})  or (False, &lt;error-message&gt;) </code></pre>
<p><strong>Example</strong></p>
<div class="codebox"><pre><code>
In [10]: s.analyze_data('pulsars', feature_select=1, impute="mean", drop=True, \
target="string", max_int_uniques=15, feature_en="mi", outlier="mad", \
max_unique_values=50)
  
Out [10]:
(True, {'artifact_id': '2c90c1dc402a4a6da37a139dfc2f7871', \
'job_id': '7871ebb62ad1458da64d800bc73019de'})
</code></pre>
</div>
<hr />
<p>DarwinSdk.<strong>analyze_model</strong>(<em>model_name, job_name=None, artifact_name=None</em>)</p>
<p>Analyze the model given its model name.</p>
<p><strong>Parameters</strong>:</p>
<ul>
<li><em>model_name</em> - The name of the model to be analyzed.</li>
<li><em>job_name</em> - (optional) If not specified, a uuid is created as the <em>job_name</em>.</li>
<li><em>artifact_name</em> - (optional) If not specified, a uuid is created as the <em>artifact_name</em>.</li>
</ul>
<p><strong>Returns</strong>:</p>
<pre> (True, {"job_name”: &lt;string&gt;, "artifact_name”: &lt;string&gt;})  or (False, &lt;error-message&gt;) 
</pre>
<p><strong>Example</strong></p>
<div class="codebox">
<pre><code>In [5]: s.analyze_model('unittest-cancer-model')
Out [5]:
(True, {'artifact_id': '71a8ae55f2934014b45c13a3975f419c', 'job_id': \
'4e59ffc425e047e1a3b872f1e7396976'})
</code></pre>
</div>
<hr /> <!--
<p>DarwinSdk.<strong>test_model</strong>(<em>dataset_name, model_name, job_name=None, artifact=None</em>)</p>
<p>Test the model given its name and a test dataset. Use <em>upload_dataset()</em> to upload a test dataset.</p>
<p><strong>Parameters</strong>:</p>
<ul>
<li><em>dataset_name</em> - The name of the dataset to use for testing the model.
</li>
<li>
<em>model_name</em> - The name of the model to be tested.
</li>
<li><em>job_name</em> - (optional) If not specified, a uuid is created as the <em>job_name</em>.</li>
<li><em>artifact_name</em> - (optional) If not specified, a uuid is created as the <em>artifact_name</em>.</li>
</ul>
<p><strong>Returns</strong>:</p>
<pre>(True, {&quot;job_id&quot;: &quot;&lt;uuid&gt;&quot;, &quot;artifact_id&quot;: &quot;&lt;uuid&gt;&quot;})  or (False, &lt;error-message&gt;)
</pre>
<p><strong>Example</strong></p>
<div class="codebox">
<pre><code>
[In [8]: s.test_model('unittest-cancer-testdataset', 'unittest-cancer-model')
Out [8]:
(True, {'artifact_id': '6691c7eb6e404343be3882baaea88444', 'job_id': \
'a3a083c8d43647959a9cd81d43923125'})

</code></pre>
</div>
<hr />   -->
<p>DarwinSdk.<strong>run_model</strong>(<em>dataset_name, model_name, supervised=True, job_name=None, artifact_name=None</em>)</p>
<p>Run the model given its name and a dataset to use. Use <strong>upload_dataset</strong>() to upload a data set.</p>
<p><strong>Parameters</strong>:</p>
<ul>
<li><em>dataset_name</em>The name of a dataset to use for running the model.
</li>
<li>
<em>model_name</em> - The name of the model to run.
</li>
<li>
<em>supervised</em> - (optional) If not specified, assumes a <em>supervised</em> model.
</li>
<li><em>job_name</em> - (optional) If not specified, a uuid is created as the <em>job_name</em>.</li>
<li><em>artifact_name</em> - (optional) If not specified, a uuid is created as the <em>artifact_name</em>.</li>
</ul>
<p><strong>Returns</strong>:</p>
<pre>(True, {"job_name”: &lt;string&gt;, "artifact_name”: &lt;string&gt;})  or (False, &lt;error-message&gt;)</pre>
<p><strong>Example</strong></p>
<div class="codebox">
<pre><code>
[In [9]: s.run_model('unittest-cancer-testdataset', 'unittest-cancer-model')
Out [9]:
(True, {'artifact_id': '6c482eac9f894cdb9b0e1e487e41730a', 'job_id': \
'1696e03c8165404c8e05685ea68baa3c'})

</code></pre>
</div>
<hr />
<p>DarwinSdk.<strong>create_risk_info</strong>(<em>failure_dataset_name, timeseries_dataset_name,  **kwargs</em>)</p>
<p>Create risk information given failure and timeseries data. Use <em>upload_dataset()</em> to upload datasets.</p>
<p><strong>Notes concerning risk</strong> - Risk is a value used in calculating future events. Risk is calculated using algorithms based on sliding time frames and associated historical data that projects forward in time to predict the likelihood of the event. The outcome of the calculations is that the likelihood of an event occurring within a particular time frame becomes available for use. Note that the risk values are dependent on the quality and extent of the historical data as well as the scope of the timeframe used for evaluation.</p>
<p><strong>Parameters</strong>:</p>
<ul>
<li>
<em>failure_dataset_name</em> - The name of a failure dataset.
</li>
<li>
<em>timeseries_dataset_name</em> - The name of a timeseries dataset.
</li>

<li>**<em>kwargs</em> - variable number of keyword arguments, described below:
	<ul>
	<li><em>job_name</em> - (optional) If not specified, a uuid is created as the <em>job_name</em>.</li>
	<li><em>artifact_name</em> - (optional) If not specified, a uuid is created as the <em>artifact_name</em>.</li>
	<li><em>risk_columns</em>: A list of column names in the index.</li>
	<li>
	<p><em>shutdown_column</em>: Name of the column in the risk data that denotes the beginning of the predicted event of interest.</p>
	</li>
	<li>
	<p><em>return_column</em>: Name of the column in the risk data that denotes the end of the predicted event <em>and</em> when all data can again be considered “normal”.</p>
	</li>
	<li>
	<p><em>asset_column</em>: Name of the asset column in the risk data. This parameter is used when the datasets consist of multiple different assets.</p>
	</li>
	<li>
	<p><em>lead_time</em>: Lead time in seconds. This value is half width of the risk function - that means. the risk index is 0 prior to <em>2* lead_time</em> and increases to 1 at a failure time.</p>
	</li>
	<li>
	<p><em>Functional_form</em>: Shape of a risk function, includes:</p>
	<ul>
	<li><code>step</code>: Step function</li>
	<li><code>linear</code>: Linear function</li>
	<li><code>sigmoid</code>: Sigmoid function</li>
	<li><code>exponential</code>: Exponential function</li>
	</ul>
	</li>
	</ul>
</li>
</ul>
<p><strong>Returns</strong>:</p>
<pre>(True, {"job_name”: &lt;string&gt;, "artifact_name”: &lt;string&gt;})  or (False, &lt;error-message&gt;)
</pre>
<p><strong>Example</strong></p>
<div class="codebox">
<pre><code>s.create_risk_info('failure-data', 'timeseries-data', return_column=\
"Date Returned to Service", shutdown_column="Shutdown Date", lead_time=1.0, \
functional_form="linear")
</code></pre>
</div>
<hr />
<h2><a name="cmethods">Convenience methods</a></h2>
<p>DarwinSdk.<strong>delete_all_datasets</strong>()</p>
<p>Deletes user datasets. This method deletes all datasets in the current user or service context.<br />
<strong>Note</strong>: Use <em>lookup_dataset()</em> to view/verify the datasets for deletion.</p>
<p><strong>Parameters</strong>: None</p>
<p><strong>Returns</strong>:</p>
<pre>    (True, None)  or (False, &lt;error-message&gt;)
</pre>
<hr />
<p>DarwinSdk.<strong>delete_all_models</strong>()</p>
<p>Delete all models for a user. This method will delete all models in the<br />
current user’s or service’s context.<br />
<strong>Note</strong>: Use <em>lookup_model()</em>  to review and verify that you want to delete all listed models.</p>
<p><strong>Parameters</strong>: None</p>
<p><strong>Returns</strong>:</p>
<pre>    (True, None)  or (False, &lt;error-message&gt;)
</pre>
<hr />
<p>DarwinSdk.<strong>wait_for_job</strong><em>(job_name, time_limit=600)</em>
<p>Synchronously wait for a job to complete, limited by <em>time_limit</em> that defaults to 600 seconds.
<p><strong>Parameters:</strong>
  <ul>
    <li><em>job_name</em> - The id for the job</li>
    <li><em>time_limit</em> - (optional) defaults to 600 seconds</li></ul>
<p><strong>Returns:</strong>:</p>
<pre>
    (True, None)  or (False, &lt;error-message&gt;)
    </pre>
<hr class="dbline"/ >
<h1><a name="reference">Reference</a></h1>
<ul>
<li><a href="#example">SDK modeling example</a></li>
<li><a href="#sadataflow">SDK analyze data workflow example</a></li>
<li><a href="#revision">Revision table</a></li>
</ul>
<h2><a name="example">SDK modeling example</a></h2>
<p>The following example shows the Darwin SDK performing a modeling process:</p>
<div class="codebox">
<pre><code>
  ---
 In [1]: from amb_sdk.sdk import DarwinSdk
 
In [2]: s = DarwinSdk()
 
In [3]:  s.auth_login_user('username', 'password')
Out[3]:
(True,
 'Bearer eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJqdGkiOiI2ZDZkMTI3Mi0wZDAxLTR\
hYmMtOWYwOC0xYWEwZmYxNDY2NjAiLCJpYXQiOjE1MTYyMTY1MTMsImV4cCI6MTUxNjIyMDExMywi\
dHlwZSI6ImFjY2VzcyIsIm5iZiI6MTUxNjIxNjUxMywiaWRlbnRpdHkiOiJjNTc2NzFjNC1lNTAwL\
TExZTctOWY4ZS1iNzk2ODU2ZTcwMGYiLCJmcmVzaCI6ZmFsc2V9.slh1mYPy_M7DqAok-tV1NT0kU\
4lAgKQoQHk6nYtetg4')
 
In [12]: s.upload_dataset('sets/cancer_train.csv', 'mydata')
Out[12]: (True, {'dataset_name': 'mydata'})
 
In [14]: s.create_model('mydata', target="Diagnosis", model_name="my-model")
Out[14]:
(True,
 {'job_name': '1661fb302af149798c34ca9db9e1b0ae', 'model_name': 'my-model'})
 
In [15]: s.wait_for_job('1661fb302af149798c34ca9db9e1b0ae')
{'percent_complete': 39, 'job_type': 'TrainModel', 'model_name': 'my-model', \
'dataset_names': ['mydata'], 'endtime': None, 'loss': 0.4169575273990631, \
'generations': 11, 'status': 'Running', 'starttime': '2018-02-01T14:16:51.4\
64827', 'artifact_names': None}
{'percent_complete': 62, 'job_type': 'TrainModel', 'model_name': 'my-model', \
'dataset_names': ['mydata'], 'endtime': None, 'loss': 0.39973780512809753, \
'generations': 17, 'status': 'Running', 'starttime': '2018-02-01T14:16:51.4\
64827', 'artifact_names': None}
{'percent_complete': 84, 'job_type': 'TrainModel', 'model_name': 'my-model', \
'dataset_names': ['mydata'], 'endtime': None, 'loss': 0.39636287093162537, \
'generations': 21, 'status': 'Running', 'starttime': '2018-02-01T14:16:51.4\
64827', 'artifact_names': None}
{'percent_complete': 100, 'job_type': 'TrainModel', 'model_name': 'my-model', \
'dataset_names': ['mydata'], 'endtime': '2018-02-01T14:18:02.072976', 'loss': \
0.39636287093162537, 'generations': 23, 'status': 'Complete', 'starttime': \
'2018-02-01T14:16:51.464827', 'artifact_names': None}
Out[15]: (True, 'Job completed')
 
In [16]: s.upload_dataset('sets/cancer_test.csv', 'mytestdata')
Out[16]: (True, {'dataset_name': 'mytestdata'})
 
In [19]: s.run_model('mytestdata', 'my-model')
Out[19]:
(True,
 {'artifact_name': '9a6d41532cec47618beee6236b02c129',
  'job_name': '91c7813334ee4c37a733761dce71c0b3'})
 
In [21]: s.wait_for_job('91c7813334ee4c37a733761dce71c0b3')
{'loss': 0.39636287093162537, 'job_type': 'RunModel', 'artifact_names': \
['9a6d41532cec47618beee6236b02c129'], 'endtime': '2018-02-01T14:22:39.05466', \
'percent_complete': 100, 'generations': 23, 'model_name': 'my-model', 'status'\
: 'Complete', 'starttime': '2018-02-01T14:22:34.219185', 'dataset_names': \
['mytestdata']}
Out[21]: (True, 'Job completed')
 
In [22]: s.download_artifact('9a6d41532cec47618beee6236b02c129') 
(True,      Diagnosis
 0       BENIGN
 1       BENIGN
 2       BENIGN
 3       BENIGN
 4       BENIGN
 5    MALIGNANT
 6    MALIGNANT
 ...
 98   MALIGNANT
 99   MALIGNANT         
  
 [100 rows x 1 columns])
</code></pre>
</div>
<hr />

<h2><a name="sadataflow">SDK analyze data workflow example</a></h2>
<p>The following example shows a Darwin SDK data analysis workflow example:</p>
 <div class="codebox">
 <pre><code>
In [1]: from amb_sdk.sdk import DarwinSdk
 
In [2]: s = DarwinSdk()
 
In [3]:  s.auth_login_user('username', 'password')
Out[3]:
(True,
 'Bearer eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJqdGkiOiI2ZDZkMTI3Mi0wZDAxLTRh\
YmMtOWYwOC0xYWEwZmYxNDY2NjAiLCJpYXQiOjE1MTYyMTY1MTMsImV4cCI6MTUxNjIyMDExMywidH\
lwZSI6ImFjY2VzcyIsIm5iZiI6MTUxNjIxNjUxMywiaWRlbnRpdHkiOiJjNTc2NzFjNC1lNTAwLTEx\
ZTctOWY4ZS1iNzk2ODU2ZTcwMGYiLCJmcmVzaCI6ZmFsc2V9.slh1mYPy_M7DqAok-tV1NT0kU4lA\
gKQoQHk6nYtetg4')
 
In [24]: s.upload_dataset('sets/pulsars.csv', 'pulsars-data')
Out[24]: (True, {'dataset_name': 'pulsars-data'})
 
In [14]: s.create_model('mydata', target="Diagnosis", model_name="my-model")
Out[14]:
(True,
 {'job_name': '1661fb302af149798c34ca9db9e1b0ae', 'model_name': 'my-model'})
 
In [15]: s.wait_for_job('1661fb302af149798c34ca9db9e1b0ae')
{'percent_complete': 39, 'job_type': 'TrainModel', 'model_name': 'my-model', \
'dataset_names': ['mydata'], 'endtime': None, 'loss': 0.4169575273990631, \
'generations': 11, 'status': 'Running', 'starttime': '2018-02-01T14:16:51.\
464827', 'artifact_names': None}
{'percent_complete': 62, 'job_type': 'TrainModel', 'model_name': 'my-model', \
'dataset_names': ['mydata'], 'endtime': None, 'loss': 0.39973780512809753, \
'generations': 17, 'status': 'Running', 'starttime': '2018-02-01T14:16:51.\
464827', 'artifact_names': None}
{'percent_complete': 84, 'job_type': 'TrainModel', 'model_name': 'my-model', \
'dataset_names': ['mydata'], 'endtime': None, 'loss': 0.39636287093162537, \
'generations': 21, 'status': 'Running', 'starttime': '2018-02-01T14:16:51.4648\
27', 'artifact_names': None}
{'percent_complete': 100, 'job_type': 'TrainModel', 'model_name': 'my-model', \
'dataset_names': ['mydata'], 'endtime': '2018-02-01T14:18:02.072976', 'loss': \
0.39636287093162537, 'generations': 23, 'status': 'Complete', 'starttime': \
'2018-02-01T14:16:51.464827', 'artifact_names': None}
Out[15]: (True, 'Job completed')
 
In [16]: s.upload_dataset('sets/cancer_test.csv', 'mytestdata')
Out[16]: (True, {'dataset_name': 'mytestdata'})
 
In [17]: s.analyze_data('pulsars-data', feature_select=None, impute="mean", \
drop=True, target=None, max_int_uniques=15, feature_eng="mi", outlier=None, \
max_unique_values=50)
Out[17]:
(True,
 {'artifact_name': '929bd117a07d411ba40d148ddd686d51',
  'job_name': '4df3e87a87224c1993120482b9b00843'})
 
In [19]: s.wait_for_job('4df3e87a87224c1993120482b9b00843')
{'starttime': '2018-02-01T15:13:05.624744', 'model_name': None, 'dataset_names'\
: ['pulsars-data'], 'artifact_names': ['929bd117a07d411ba40d148ddd686d51'], \
'percent_complete': 100, 'job_type': 'AnalyzeData', 'endtime': '2018-02-01T15:\
13:09.0199', 'generations': None, 'loss': None, 'status': 'Complete'}
Out[19]: (True, 'Job completed')
 
In [20]: s.download_artifact('929bd117a07d411ba40d148ddd686d51')
Out[20]:
(True,   categories      col_name     col_type      max     mean       min  \
 0       None  mean_profile    numerical  180.219  95.3869    5.8125  
 1       None   std_profile    numerical  91.8086  44.3984    24.772  
 2       None  kurt_profile    numerical  8.06952  1.24083  -1.60483  
 3       None  skew_profile    numerical  68.1016  5.72565  -1.78189  
 4       None    mean_dmsnr    numerical  222.421   23.786  0.273411  
 5       None     std_dmsnr    numerical  110.642   35.272   7.56568  
 6       None    kurt_dmsnr    numerical  32.1986  6.66098  -3.13927  
 7       None    skew_dmsnr    numerical  1072.96  79.4015  -1.97698  
 8        0,1         class  categorical     None     None      None  
  
    num_categories      std 
 0          3939.0  36.4588 
 1          4635.0  8.03585 
 2          4639.0  1.80623 
 3          4639.0  11.0723 
 4          4012.0  39.2822 
 5          4639.0  23.9892 
 6          4639.0  4.87737 
 7          4639.0   103.01 
 8             2.0     None  )
 </code></pre>
  </div>
<hr />


<h2><a name="revision">Revision Table</a></h2>
<table border="1">
<thead>
<tr>
<th>Version</th>
<th>Author</th>
<th>Date</th>
<th>Notes</th>
</tr>
</thead>
<tbody>
<tr>
<td>v 1.0</td>
<td> SparkCognition, SCheng</td>
<td>02.05.2018</td>
<td>First Release</td>
</tr>
</tbody>
</table>


</body>
</html>
