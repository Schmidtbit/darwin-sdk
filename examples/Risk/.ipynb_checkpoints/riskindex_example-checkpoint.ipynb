{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "from amb_sdk.sdk import DarwinSdk\n",
    "from time import sleep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Set Darwin SDK\n",
    "ds = DarwinSdk()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Register user [if you are not yet resigtered]\n",
    "\"\"\"\n",
    "api_key = ''\n",
    "status, msg = ds.auth_login('password', api_key)\n",
    "if not status:\n",
    "    print(msg)\n",
    "status, msg = ds.auth_register_user('username', 'password','email@emailaddress.com')\n",
    "if not status:\n",
    "    print(msg)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Login, User, ONE\n",
    "status, msg = ds.auth_login_user('username','login')\n",
    "if not status:\n",
    "    print(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set local path to files - Please update to reflect your machine\n",
    "path = '/Users/kmoore/amb-sdk/sets/risk_example/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# upload failure date data\n",
    "(code, response) = ds.upload_dataset(path+'sets/failures.csv', 'unittest-failures-data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#upload timeseries data\n",
    "(code, response) = ds.upload_dataset(path+'sets/sensor_ts.csv', 'unittest-timeseries-data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# lead time is unit in seconds; leadtime is the half width of the riskindex\n",
    "lead_time = 3600 * 24 * 3.5 # half week risk \n",
    "(code, response) = ds.create_risk_info('unittest-failures-data', 'unittest-timeseries-data',\n",
    "                                        return_column=\"Date Returned to Service\",\n",
    "                                        shutdown_column=\"Shutdown Date\",\n",
    "                                        lead_time=lead_time, functional_form=\"sigmoid\")\n",
    "\n",
    "ds.wait_for_job(response['job_name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# download the artifact (riskindex)\n",
    "status, response = ds.download_artifact(response['artifact_name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_risk = pd.read_csv(response['filename'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# read timeseries data for datetime index\n",
    "df_ts = pd.read_csv(path+'sets/sensor_ts.csv')\n",
    "df_ts['datetime'] = pd.to_datetime(df_ts['datetime'], errors='coerce')\n",
    "\n",
    "# concatenate two df\n",
    "df = pd.concat([df_ts, df_risk], axis=1)\n",
    "\n",
    "# set datetime index\n",
    "df= df.set_index('datetime')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['risk'].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# see the failures\n",
    "df_failure = pd.read_csv(path+'sets/failures.csv')\n",
    "df_failure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# let's zoom-in the date around 2012-02-10 failure date\n",
    "df['risk']['2012-01-25':'2012-02-12'].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#View full file upon which you can build a model and convert to csv\n",
    "df.to_csv(\"assetrisk.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Upload Full CSV to Darwin for predictions\n",
    "(code, response) = ds.upload_dataset(path+'assetrisk.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Build model\n",
    "target = \"risk\"\n",
    "model = target + \"_model0\"\n",
    "status, job_id = ds.create_model(dataset_names = 'assetrisk.csv', \\\n",
    "                                 target = target, \\\n",
    "                                 model_name =  model, \\\n",
    "                                 max_train_time = '00:10'#,\\\n",
    "                                 #feature_eng = 'auc'\n",
    "                                )\n",
    "if status:\n",
    "    ds.wait_for_job(job_id['job_name'])\n",
    "else:\n",
    "    print(job_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Run Predictions    \n",
    "status, artifact = ds.run_model('assetrisk.csv', model)\n",
    "sleep(1)\n",
    "ds.wait_for_job(artifact['job_name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Get predictions\n",
    "status, prediction = ds.download_artifact(artifact['artifact_name'])\n",
    "if status:\n",
    "    ds.wait_for_job(job_id['job_name'])\n",
    "else:\n",
    "    print(job_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Rename\n",
    "prediction = prediction.rename(columns={target:target+'_pred' })\n",
    "\n",
    "df = df.reset_index()\n",
    "\n",
    "# concatenate two df\n",
    "df = pd.concat([df, prediction], axis=1)\n",
    "\n",
    "# set datetime index\n",
    "df= df.set_index('datetime')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Plot predictions vs actual\n",
    "df[target].plot()\n",
    "df[target+'_pred'].plot()\n",
    "#plt.legend(['Predicted','Actual'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Delete all models and datasets\n",
    "#ds.delete_all_datasets()\n",
    "#ds.delete_all_models()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
